# -*- coding: utf-8 -*-
"""Prediction_RNA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1enXXrIwsPaveKOXbtEkHmA4M_-l4xl8C
"""

!cat /proc/meminfo | grep Mem

!pip install pandas openpyxl
import pandas as pd

import os
os.listdir('/content')

lnc_file = '/content/lncRNA_log2FC_H37Rv_1h_filtered.csv'
mRNA_file = '/content/mRNA_log2FC_H37Rv_1h_filtered.csv'

lnc_df = pd.read_csv(lnc_file)
mRNA_df = pd.read_csv(mRNA_file)

lnc_genes = lnc_df['Table.1'].dropna().unique()
mRNA_genes = mRNA_df['Table.1'].dropna().unique()
print("lncRNAs:", lnc_genes[:5])
print("mRNAs:", mRNA_genes[:5])

print(len(lnc_genes))
print(len(mRNA_genes))

!curl -o miRNA_lncRNA_all.txt \
 "https://rnasysu.com/encori/api/miRNATarget/\
?assembly=hg38&geneType=lncRNA&miRNA=all&clipExpNum=1&degraExpNum=0&pancancerNum=0&programNum=0&program=None&target=all&cellType=all"

!curl -o miRNA_mRNA_all.txt \
 "https://rnasysu.com/encori/api/miRNATarget/\
?assembly=hg38&geneType=mRNA&miRNA=all&clipExpNum=1&degraExpNum=0&pancancerNum=0&programNum=0&program=None&target=all&cellType=all"

import pandas as pd

# Path to files
lncrna_file = '/content/miRNA‚ÄìlncRNA.txt'  # adjust path & name if needed
mrna_file = '/content/mirna_mrna.txt'      # adjust path & name if needed

# Load lncRNA‚ÄìmiRNA
lnc_df = pd.read_csv(lncrna_file, sep='\t', low_memory=False)
print(lnc_df.head())

# For very large file: read in chunks
chunks = []
chunk_size = 10**6  # 1 million rows per chunk
for chunk in pd.read_csv(mrna_file, sep='\t', chunksize=chunk_size):
    chunks.append(chunk)

mrna_df = pd.concat(chunks, ignore_index=True)
print(mrna_df.head())

chunks = []
chunk_size = 10**6  # 1 million rows per chunk
for chunk in pd.read_csv(mrna_file, sep='\t', chunksize=chunk_size, encoding='latin1'):
    chunks.append(chunk)

mrna_df = pd.concat(chunks, ignore_index=True)
print(mrna_df.head())

mrna_filtered = mrna_df[mrna_df['actor2'].isin(mRNA_genes)]
mrna_filtered.to_csv('mRNA_miRNA_filtered.csv', index=False)
print(mrna_filtered.shape)

"""##This is for 1H timefreame of H37Rv"""

# Paths to DE files you uploaded
de_mrna_file = '/content/mRNA_log2FC_H37Rv_1h_filtered.csv'
de_lnc_file = '/content/lncRNA_log2FC_H37Rv_1h_filtered.csv'

# Read DE gene lists
de_mrna_df = pd.read_csv(de_mrna_file)
de_lnc_df = pd.read_csv(de_lnc_file)

# Get gene name arrays
mRNA_genes = de_mrna_df['Table.1'].dropna().unique()
lnc_genes = de_lnc_df['Table.1'].dropna().unique()

print(f"DE mRNAs: {len(mRNA_genes)}, DE lncRNAs: {len(lnc_genes)}")

lncraid_file = '/content/miRNA‚ÄìlncRNA.txt'
mrnaraid_file = '/content/mirna_mrna.txt'

# Read both datasets (encoding='latin1' to avoid Unicode errors)
lnc_df = pd.read_csv(lncraid_file, sep='\t', encoding='latin1', low_memory=False)
mrna_df = pd.read_csv(mrnaraid_file, sep='\t', encoding='latin1', low_memory=False)

print(f"RAID lncRNA‚ÄìmiRNA: {lnc_df.shape}, RAID miRNA‚ÄìmRNA: {mrna_df.shape}")

# lncRNA‚ÄìmiRNA
lnc_filtered = lnc_df[lnc_df['actor1'].isin(lnc_genes) | lnc_df['actor2'].isin(lnc_genes)]
lnc_filtered.to_csv('lncRNA_miRNA_filtered.csv', index=False)
print(f"Filtered lncRNA‚ÄìmiRNA: {lnc_filtered.shape}")

# miRNA‚ÄìmRNA
mrna_filtered = mrna_df[mrna_df['actor2'].isin(mRNA_genes)]
mrna_filtered.to_csv('mRNA_miRNA_filtered.csv', index=False)
print(f"Filtered miRNA‚ÄìmRNA: {mrna_filtered.shape}")

print(lnc_filtered.columns)
print(lnc_filtered.head())

print(lnc_genes[:10])
print(lnc_df['actor1'].unique()[:10])
print(lnc_df['actor2'].unique()[:10])

lnc_genes_clean = [name.split('-')[1] for name in lnc_genes]
print(lnc_genes_clean[:10])

lnc_filtered = lnc_df[
    (lnc_df['actor1'].isin(lnc_genes_clean)) & (lnc_df['cat1'] == 'lncRNA')
]
print(lnc_filtered.shape)

lnc_filtered.to_csv('lncRNA_miRNA_filtered.csv', index=False)

cerna_triplets = pd.merge(
    lnc_filtered,
    mrna_filtered,
    left_on='actor2',
    right_on='actor1',
    suffixes=('_lncRNA', '_mRNA')
)

print(cerna_triplets.columns)

print(cerna_triplets.columns.tolist())

cerna_triplets_final = cerna_triplets[['actor1_lncRNA', 'actor2_lncRNA', 'actor2_mRNA']]
cerna_triplets_final.columns = ['lncRNA', 'miRNA', 'mRNA']

cerna_triplets_final.to_csv('ceRNA_triplets.csv', index=False)
print(f"ceRNA triplets: {cerna_triplets_final.shape}")

import matplotlib.pyplot as plt
import seaborn as sns

# Clip extreme outliers for visualization
de_mrna_df_clipped = de_mrna_df.copy()
de_mrna_df_clipped['log2FC'] = de_mrna_df_clipped['log2FC'].clip(-10, 10)

plt.figure(figsize=(4,6))
sns.violinplot(y=de_mrna_df_clipped['log2FC'], width=0.4, inner='box', color='skyblue')
plt.title("Log2FC distribution of DE mRNAs", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("")
plt.tight_layout()
plt.savefig("DE_mRNAs_violin_300dpi.png", dpi=300)
plt.show()

upregulated = (de_mrna_df['log2FC'] > 0).sum()
downregulated = (de_mrna_df['log2FC'] < 0).sum()

plt.figure(figsize=(5,5))
sns.barplot(x=['Upregulated', 'Downregulated'], y=[upregulated, downregulated], palette='viridis')
plt.ylabel("Number of genes", fontsize=10)
plt.title("Upregulated vs Downregulated DE mRNAs", fontsize=12)
plt.tight_layout()
plt.savefig("DE_mRNAs_up_down_bar_300dpi.png", dpi=300)
plt.show()

# Clip extreme outliers
de_lnc_df_clipped = de_lnc_df.copy()
de_lnc_df_clipped['log2FC'] = de_lnc_df_clipped['log2FC'].clip(-10, 10)

de_mrna_df_clipped['type'] = 'mRNA'
de_lnc_df_clipped['type'] = 'lncRNA'

combined_df = pd.concat([
    de_mrna_df_clipped[['log2FC', 'type']],
    de_lnc_df_clipped[['log2FC', 'type']]
])

plt.figure(figsize=(6,6))
sns.violinplot(x='type', y='log2FC', data=combined_df, inner='box', width=0.4, palette='pastel')
plt.title("Log2FC distribution of DE mRNAs and DE lncRNAs", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("")
plt.tight_layout()
plt.savefig("DE_mRNAs_lncRNAs_combined_violin_300dpi.png", dpi=300)
plt.show()

"""### This is others timefreame for H37RA and H37Rv"""

import pandas as pd

# Define timepoints and strains
timepoints = ['1h', '4h', '12h', '24h', '48h']
strains = ['H37Rv', 'H37Ra']

# RAID files (already uploaded)
lncraid_file = '/content/miRNA‚ÄìlncRNA.txt'
mrnaraid_file = '/content/mirna_mrna.txt'

lnc_df = pd.read_csv(lncraid_file, sep='\t', encoding='latin1', low_memory=False)
mrna_df = pd.read_csv(mrnaraid_file, sep='\t', encoding='latin1', low_memory=False)

for strain in strains:
    for tp in timepoints:
        print(f"Processing: {strain} {tp}")

        # Load DE files for this strain and timepoint
        de_mrna_file = f'/content/mRNA_log2FC_{strain}_{tp}_filtered.csv'
        de_lnc_file = f'/content/lncRNA_log2FC_{strain}_{tp}_filtered.csv'

        de_mrna_df = pd.read_csv(de_mrna_file)
        de_lnc_df = pd.read_csv(de_lnc_file)

        mRNA_genes = de_mrna_df['Table.1'].dropna().unique()
        lnc_genes = de_lnc_df['Table.1'].dropna().unique()

        # Clean lncRNA names
        lnc_genes_clean = [name.split('-')[1] for name in lnc_genes]

        # Filter RAID
        lnc_filtered = lnc_df[
            (lnc_df['actor1'].isin(lnc_genes_clean)) & (lnc_df['cat1'] == 'lncRNA')
        ]
        mrna_filtered = mrna_df[
            mrna_df['actor2'].isin(mRNA_genes)
        ]

        # Merge to ceRNA triplets
        cerna_triplets = pd.merge(
            lnc_filtered,
            mrna_filtered,
            left_on='actor2',
            right_on='actor1',
            suffixes=('_lncRNA', '_mRNA')
        )

        # Keep relevant columns
        cerna_triplets_final = cerna_triplets[['actor1_lncRNA', 'actor2_lncRNA', 'actor2_mRNA']]
        cerna_triplets_final.columns = ['lncRNA', 'miRNA', 'mRNA']

        # Save
        outfile = f'ceRNA_triplets_{strain}_{tp}.csv'
        cerna_triplets_final.to_csv(outfile, index=False)

        print(f"Saved: {outfile} ({cerna_triplets_final.shape[0]} triplets)")

print("‚úÖ All timepoints and strains processed.")

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strains = ['H37Rv', 'H37Ra']

counts = []

for strain in strains:
    for tp in timepoints:
        file = f'ceRNA_triplets_{strain}_{tp}.csv'
        df = pd.read_csv(file)
        counts.append({'strain': strain, 'timepoint': tp, 'triplets': df.shape[0]})

counts_df = pd.DataFrame(counts)

plt.figure(figsize=(8,6))
for strain in strains:
    subset = counts_df[counts_df['strain']==strain]
    plt.plot(subset['timepoint'], subset['triplets'], marker='o', label=strain)

plt.title("Number of ceRNA triplets over time")
plt.xlabel("Timepoint")
plt.ylabel("Number of triplets")
plt.legend()
plt.tight_layout()
plt.savefig("ceRNA_triplets_over_time_300dpi.png", dpi=300)
plt.show()

import pandas as pd

timepoints = ['1h', '4h', '12h', '24h', '48h']
strains = ['H37Rv', 'H37Ra']

for strain in strains:
    for tp in timepoints:
        print(f"Processing hubs: {strain} {tp}")

        triplet_file = f'ceRNA_triplets_{strain}_{tp}.csv'
        df = pd.read_csv(triplet_file)

        # Count lncRNAs
        lnc_counts = df['lncRNA'].value_counts().reset_index()
        lnc_counts.columns = ['lncRNA', 'count']
        lnc_counts.to_csv(f'top_lncRNAs_{strain}_{tp}.csv', index=False)

        # Count mRNAs
        mrna_counts = df['mRNA'].value_counts().reset_index()
        mrna_counts.columns = ['mRNA', 'count']
        mrna_counts.to_csv(f'top_mRNAs_{strain}_{tp}.csv', index=False)

        print(f"‚úÖ Saved: top_lncRNAs_{strain}_{tp}.csv & top_mRNAs_{strain}_{tp}.csv")

print("‚úÖ Step 1 completed: hub lncRNAs & mRNAs identified.")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'   # üî∑ change to 'H37Ra' if needed
entity = 'lncRNA'  # üî∑ or 'mRNA'

# Read hub counts for each timepoint
hub_data = {}

for tp in timepoints:
    file = f'top_{entity}s_{strain}_{tp}.csv'
    df = pd.read_csv(file)
    hub_data[tp] = df.set_index(entity)['count']

# Combine into a single DataFrame
heatmap_df = pd.concat(hub_data, axis=1).fillna(0)
heatmap_df.columns.name = 'Timepoint'

# Take top 10 overall hubs
top_entities = heatmap_df.sum(axis=1).sort_values(ascending=False).head(10).index
heatmap_df = heatmap_df.loc[top_entities]

# Plot heatmap
plt.figure(figsize=(10,8))
sns.heatmap(heatmap_df, annot=True, fmt=".0f", cmap='Blues')
plt.title(f"Top 10 {entity} hubs dynamics over time ({strain})", fontsize=12)
plt.ylabel(entity)
plt.xlabel("Timepoint")
plt.tight_layout()
plt.savefig(f"heatmap_top10_{entity}_hubs_{strain}.png", dpi=300)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'   # üî∑ change to 'H37Ra' if needed
entity = 'lncRNA'  # üî∑ or 'mRNA'

# Read hub counts for each timepoint
hub_data = {}

for tp in timepoints:
    file = f'top_{entity}s_{strain}_{tp}.csv'
    df = pd.read_csv(file)
    hub_data[tp] = df.set_index(entity)['count']

# Combine into a single DataFrame
heatmap_df = pd.concat(hub_data, axis=1).fillna(0)
heatmap_df.columns.name = 'Timepoint'

# Take top 10 overall hubs
top_entities = heatmap_df.sum(axis=1).sort_values(ascending=False).head(10).index
heatmap_df = heatmap_df.loc[top_entities]

# Plot heatmap
plt.figure(figsize=(10,8), dpi=300)
sns.set(font_scale=1.2)
sns.heatmap(
    heatmap_df,
    annot=True,
    fmt=".0f",
    cmap='YlGnBu',       # üåà lighter, visually appealing palette
    linewidths=0.5,
    cbar_kws={"shrink": 0.7}
)
plt.title(f"Top 10 {entity} hubs dynamics over time ({strain})", fontsize=14)
plt.ylabel(entity, fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.tight_layout()
plt.savefig(f"heatmap_top10_{entity}_hubs_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'   # üî∑ change to 'H37Ra' if needed
entity = 'mRNA'  # üî∑ or 'mRNA'

# Read hub counts for each timepoint
hub_data = {}

for tp in timepoints:
    file = f'top_{entity}s_{strain}_{tp}.csv'
    df = pd.read_csv(file)
    hub_data[tp] = df.set_index(entity)['count']

# Combine into a single DataFrame
heatmap_df = pd.concat(hub_data, axis=1).fillna(0)
heatmap_df.columns.name = 'Timepoint'

# Take top 10 overall hubs
top_entities = heatmap_df.sum(axis=1).sort_values(ascending=False).head(10).index
heatmap_df = heatmap_df.loc[top_entities]

# Plot heatmap
plt.figure(figsize=(10,8), dpi=300)
sns.set(font_scale=1.2)
sns.heatmap(
    heatmap_df,
    annot=True,
    fmt=".0f",
    cmap='YlGnBu',       # üåà lighter, visually appealing palette
    linewidths=0.5,
    cbar_kws={"shrink": 0.7}
)
plt.title(f"Top 10 {entity} hubs dynamics over time ({strain})", fontsize=14)
plt.ylabel(entity, fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.tight_layout()
plt.savefig(f"heatmap_top10_{entity}_hubs_{strain}_300dpi.png", dpi=300)
plt.show()

pd.read_csv('lncRNA_log2FC_H37Rv_1h_filtered.csv').columns

pd.read_csv('top_lncRNAs_H37Rv_1h.csv').columns

pd.read_csv('top_lncRNAs_H37Rv_1h.csv').head()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'
entity = 'lncRNA'
top_n = 10

hub_log2fc = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Extract gene symbol from Table.1
    de_df['gene_symbol'] = de_df['Table.1'].apply(lambda x: x.split('-')[1])

    # Read hub file
    hub_file = f'top_{entity}s_{strain}_{tp}.csv'
    hub_df = pd.read_csv(hub_file).head(top_n)

    # Subset DE to hubs
    hubs_in_de = de_df[de_df['gene_symbol'].isin(hub_df[entity])]
    hubs_in_de['Timepoint'] = tp

    hub_log2fc.append(hubs_in_de[['gene_symbol', 'log2FC', 'Timepoint']])

# Combine all timepoints
hub_log2fc_df = pd.concat(hub_log2fc)

# Plot
plt.figure(figsize=(10,6), dpi=300)
sns.violinplot(
    x='Timepoint',
    y='log2FC',
    data=hub_log2fc_df,
    inner='box',
    palette='pastel'
)
plt.title(f"Log2FC distribution of top {top_n} {entity} hubs over time ({strain})", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("Timepoint", fontsize=10)
plt.tight_layout()
plt.savefig(f"violin_top{top_n}_{entity}_log2FC_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Ra'    # Change to H37Ra here
entity = 'mRNA'     # Change to mRNA here
top_n = 10

hub_log2fc = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # For lncRNA, extract gene symbol
    if entity == 'lncRNA':
        de_df['gene_symbol'] = de_df['Table.1'].apply(lambda x: x.split('-')[1])
    else:
        de_df['gene_symbol'] = de_df['Table.1']

    # Read hub file
    hub_file = f'top_{entity}s_{strain}_{tp}.csv'
    hub_df = pd.read_csv(hub_file).head(top_n)

    # Subset DE to hubs
    hubs_in_de = de_df[de_df['gene_symbol'].isin(hub_df[entity])]
    hubs_in_de['Timepoint'] = tp

    hub_log2fc.append(hubs_in_de[['gene_symbol', 'log2FC', 'Timepoint']])

# Combine all timepoints
hub_log2fc_df = pd.concat(hub_log2fc)

# Plot
plt.figure(figsize=(10,6), dpi=300)
sns.violinplot(
    x='Timepoint',
    y='log2FC',
    data=hub_log2fc_df,
    inner='box',
    palette='pastel'
)
plt.title(f"Log2FC distribution of top {top_n} {entity} hubs over time ({strain})", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("Timepoint", fontsize=10)
plt.tight_layout()
plt.savefig(f"violin_top{top_n}_{entity}_log2FC_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Ra'
entity = 'lncRNA'
top_n = 10

hub_log2fc = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Extract gene symbol from Table.1
    de_df['gene_symbol'] = de_df['Table.1'].apply(lambda x: x.split('-')[1])

    # Read hub file
    hub_file = f'top_{entity}s_{strain}_{tp}.csv'
    hub_df = pd.read_csv(hub_file).head(top_n)

    # Subset DE to hubs
    hubs_in_de = de_df[de_df['gene_symbol'].isin(hub_df[entity])]
    hubs_in_de['Timepoint'] = tp

    hub_log2fc.append(hubs_in_de[['gene_symbol', 'log2FC', 'Timepoint']])

# Combine all timepoints
hub_log2fc_df = pd.concat(hub_log2fc)

# Plot
plt.figure(figsize=(10,6), dpi=300)
sns.violinplot(
    x='Timepoint',
    y='log2FC',
    data=hub_log2fc_df,
    inner='box',
    palette='pastel'
)
plt.title(f"Log2FC distribution of top {top_n} {entity} hubs over time ({strain})", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("Timepoint", fontsize=10)
plt.tight_layout()
plt.savefig(f"violin_top{top_n}_{entity}_log2FC_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'    # Change to H37Ra here
entity = 'mRNA'     # Change to mRNA here
top_n = 10

hub_log2fc = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # For lncRNA, extract gene symbol
    if entity == 'lncRNA':
        de_df['gene_symbol'] = de_df['Table.1'].apply(lambda x: x.split('-')[1])
    else:
        de_df['gene_symbol'] = de_df['Table.1']

    # Read hub file
    hub_file = f'top_{entity}s_{strain}_{tp}.csv'
    hub_df = pd.read_csv(hub_file).head(top_n)

    # Subset DE to hubs
    hubs_in_de = de_df[de_df['gene_symbol'].isin(hub_df[entity])]
    hubs_in_de['Timepoint'] = tp

    hub_log2fc.append(hubs_in_de[['gene_symbol', 'log2FC', 'Timepoint']])

# Combine all timepoints
hub_log2fc_df = pd.concat(hub_log2fc)

# Plot
plt.figure(figsize=(10,6), dpi=300)
sns.violinplot(
    x='Timepoint',
    y='log2FC',
    data=hub_log2fc_df,
    inner='box',
    palette='pastel'
)
plt.title(f"Log2FC distribution of top {top_n} {entity} hubs over time ({strain})", fontsize=12)
plt.ylabel("log2FC", fontsize=10)
plt.xlabel("Timepoint", fontsize=10)
plt.tight_layout()
plt.savefig(f"violin_top{top_n}_{entity}_log2FC_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'    # Change to 'H37Ra' as needed
entity = 'mRNA'     # Change to 'lncRNA' as needed

up_counts = []
down_counts = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Count up & down
    up = (de_df['log2FC'] > 1).sum()
    down = (de_df['log2FC'] < -1).sum()

    up_counts.append(up)
    down_counts.append(down)

# Create dataframe for plotting
df = pd.DataFrame({
    'Timepoint': timepoints,
    'Upregulated': up_counts,
    'Downregulated': down_counts
}).set_index('Timepoint')

# Plot
plt.figure(figsize=(8,6), dpi=300)
df.plot(
    kind='bar',
    stacked=True,
    color=['#4CAF50', '#F44336'],
    figsize=(8,6),
    rot=0
)
plt.title(f"Up- and Down-regulated DE {entity}s over time ({strain})", fontsize=12)
plt.ylabel("Number of genes", fontsize=10)
plt.xlabel("Timepoint", fontsize=10)
plt.tight_layout()
plt.savefig(f"DE_{entity}_up_down_barplot_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'    # Change to 'H37Ra' if needed
entity = 'mRNA'     # Change to 'lncRNA' if needed

up_counts = []
down_counts = []
up_genes_all = []
down_genes_all = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Find up & down genes
    up_genes = de_df[de_df['log2FC'] > 1]['Table.1'].tolist()
    down_genes = de_df[de_df['log2FC'] < -1]['Table.1'].tolist()

    # Save counts
    up_counts.append(len(up_genes))
    down_counts.append(len(down_genes))

    # Save gene lists
    up_df = pd.DataFrame({'Gene': up_genes, 'Regulation': 'Up', 'Timepoint': tp})
    down_df = pd.DataFrame({'Gene': down_genes, 'Regulation': 'Down', 'Timepoint': tp})
    up_genes_all.append(up_df)
    down_genes_all.append(down_df)

# Save gene lists to CSV
combined_df = pd.concat(up_genes_all + down_genes_all)
combined_df.to_csv(f"DE_{entity}_up_down_genes_{strain}.csv", index=False)

# Create dataframe for barplot
df = pd.DataFrame({
    'Timepoint': timepoints,
    'Upregulated': up_counts,
    'Downregulated': down_counts
}).set_index('Timepoint')

# Plot
plt.figure(figsize=(8,6), dpi=300)
barplot = df.plot(
    kind='bar',
    stacked=True,
    color=['#6BAED6', '#FB6A4A'],  # blue & red
    figsize=(8,6),
    rot=0
)
plt.title(f"Up- and Down-regulated DE {entity}s over time ({strain})", fontsize=14)
plt.ylabel("Number of genes", fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Place legend outside
plt.legend(
    title='Regulation',
    bbox_to_anchor=(1.05, 1),
    loc='upper left',
    fontsize=10
)

plt.tight_layout()
plt.savefig(f"DE_{entity}_up_down_barplot_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Rv'    # Change to 'H37Ra' if needed
entity = 'lncRNA'     # Change to 'lncRNA' if needed

up_counts = []
down_counts = []
up_genes_all = []
down_genes_all = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Find up & down genes
    up_genes = de_df[de_df['log2FC'] > 1]['Table.1'].tolist()
    down_genes = de_df[de_df['log2FC'] < -1]['Table.1'].tolist()

    # Save counts
    up_counts.append(len(up_genes))
    down_counts.append(len(down_genes))

    # Save gene lists
    up_df = pd.DataFrame({'Gene': up_genes, 'Regulation': 'Up', 'Timepoint': tp})
    down_df = pd.DataFrame({'Gene': down_genes, 'Regulation': 'Down', 'Timepoint': tp})
    up_genes_all.append(up_df)
    down_genes_all.append(down_df)

# Save gene lists to CSV
combined_df = pd.concat(up_genes_all + down_genes_all)
combined_df.to_csv(f"DE_{entity}_up_down_genes_{strain}.csv", index=False)

# Create dataframe for barplot
df = pd.DataFrame({
    'Timepoint': timepoints,
    'Upregulated': up_counts,
    'Downregulated': down_counts
}).set_index('Timepoint')

# Plot
plt.figure(figsize=(8,6), dpi=300)
barplot = df.plot(
    kind='bar',
    stacked=True,
    color=['#6BAED6', '#FB6A4A'],  # blue & red
    figsize=(8,6),
    rot=0
)
plt.title(f"Up- and Down-regulated DE {entity}s over time ({strain})", fontsize=14)
plt.ylabel("Number of genes", fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Place legend outside
plt.legend(
    title='Regulation',
    bbox_to_anchor=(1.05, 1),
    loc='upper left',
    fontsize=10
)

plt.tight_layout()
plt.savefig(f"DE_{entity}_up_down_barplot_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Ra'    # Change to 'H37Ra' if needed
entity = 'lncRNA'     # Change to 'lncRNA' if needed

up_counts = []
down_counts = []
up_genes_all = []
down_genes_all = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Find up & down genes
    up_genes = de_df[de_df['log2FC'] > 1]['Table.1'].tolist()
    down_genes = de_df[de_df['log2FC'] < -1]['Table.1'].tolist()

    # Save counts
    up_counts.append(len(up_genes))
    down_counts.append(len(down_genes))

    # Save gene lists
    up_df = pd.DataFrame({'Gene': up_genes, 'Regulation': 'Up', 'Timepoint': tp})
    down_df = pd.DataFrame({'Gene': down_genes, 'Regulation': 'Down', 'Timepoint': tp})
    up_genes_all.append(up_df)
    down_genes_all.append(down_df)

# Save gene lists to CSV
combined_df = pd.concat(up_genes_all + down_genes_all)
combined_df.to_csv(f"DE_{entity}_up_down_genes_{strain}.csv", index=False)

# Create dataframe for barplot
df = pd.DataFrame({
    'Timepoint': timepoints,
    'Upregulated': up_counts,
    'Downregulated': down_counts
}).set_index('Timepoint')

# Plot
plt.figure(figsize=(8,6), dpi=300)
barplot = df.plot(
    kind='bar',
    stacked=True,
    color=['#6BAED6', '#FB6A4A'],  # blue & red
    figsize=(8,6),
    rot=0
)
plt.title(f"Up- and Down-regulated DE {entity}s over time ({strain})", fontsize=14)
plt.ylabel("Number of genes", fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Place legend outside
plt.legend(
    title='Regulation',
    bbox_to_anchor=(1.05, 1),
    loc='upper left',
    fontsize=10
)

plt.tight_layout()
plt.savefig(f"DE_{entity}_up_down_barplot_{strain}_300dpi.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

timepoints = ['1h', '4h', '12h', '24h', '48h']
strain = 'H37Ra'    # Change to 'H37Ra' if needed
entity = 'mRNA'     # Change to 'lncRNA' if needed

up_counts = []
down_counts = []
up_genes_all = []
down_genes_all = []

for tp in timepoints:
    # Read DE file
    de_file = f'{entity}_log2FC_{strain}_{tp}_filtered.csv'
    de_df = pd.read_csv(de_file)

    # Find up & down genes
    up_genes = de_df[de_df['log2FC'] > 1]['Table.1'].tolist()
    down_genes = de_df[de_df['log2FC'] < -1]['Table.1'].tolist()

    # Save counts
    up_counts.append(len(up_genes))
    down_counts.append(len(down_genes))

    # Save gene lists
    up_df = pd.DataFrame({'Gene': up_genes, 'Regulation': 'Up', 'Timepoint': tp})
    down_df = pd.DataFrame({'Gene': down_genes, 'Regulation': 'Down', 'Timepoint': tp})
    up_genes_all.append(up_df)
    down_genes_all.append(down_df)

# Save gene lists to CSV
combined_df = pd.concat(up_genes_all + down_genes_all)
combined_df.to_csv(f"DE_{entity}_up_down_genes_{strain}.csv", index=False)

# Create dataframe for barplot
df = pd.DataFrame({
    'Timepoint': timepoints,
    'Upregulated': up_counts,
    'Downregulated': down_counts
}).set_index('Timepoint')

# Plot
plt.figure(figsize=(8,6), dpi=300)
barplot = df.plot(
    kind='bar',
    stacked=True,
    color=['#6BAED6', '#FB6A4A'],  # blue & red
    figsize=(8,6),
    rot=0
)
plt.title(f"Up- and Down-regulated DE {entity}s over time ({strain})", fontsize=14)
plt.ylabel("Number of genes", fontsize=12)
plt.xlabel("Timepoint", fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Place legend outside
plt.legend(
    title='Regulation',
    bbox_to_anchor=(1.05, 1),
    loc='upper left',
    fontsize=10
)

plt.tight_layout()
plt.savefig(f"DE_{entity}_up_down_barplot_{strain}_300dpi.png", dpi=300)
plt.show()

pd.read_csv('mRNA_log2FC_H37Rv_1h_filtered.csv').columns

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import glob

# Define patterns
files = sorted(glob.glob("ceRNA_triplets_*.csv"))

merged_df = pd.DataFrame()

for file in files:
    df = pd.read_csv(file)

    # Parse strain & timepoint from filename
    name_parts = file.replace(".csv", "").split("_")
    strain = name_parts[2]
    timepoint = name_parts[3]

    df['strain'] = strain
    df['timepoint'] = timepoint

    merged_df = pd.concat([merged_df, df], ignore_index=True)

print(f"Merged shape: {merged_df.shape}")
print(merged_df.head())

# Save to file
merged_df.to_csv("ceRNA_triplets_merged.csv", index=False)
print("Merged file saved as ceRNA_triplets_merged.csv")

import pandas as pd
import glob

# Define patterns
files = sorted(glob.glob("ceRNA_triplets_*.csv"))

# Create empty output file with header
first = True

for file in files:
    df = pd.read_csv(file)

    # Parse strain & timepoint from filename
    name_parts = file.replace(".csv", "").split("_")
    strain = name_parts[2]
    timepoint = name_parts[3]

    df['strain'] = strain
    df['timepoint'] = timepoint

    # Append to output file
    df.to_csv("ceRNA_triplets_merged.csv", mode='a', index=False, header=first)
    first = False  # Only keep header in first write

print("Merged file saved as ceRNA_triplets_merged.csv")

import pandas as pd
import glob
import gc

# ‚úÖ Define your columns of interest here (optional)
# if you want to keep ALL columns, set this to None
columns_to_keep = None   # e.g., ['source', 'target', 'weight', 'strain', 'timepoint']

# ‚úÖ Output file name
output_file = "ceRNA_triplets_merged.txt"

# üî∑ Find all matching CSV files
files = sorted(glob.glob("ceRNA_triplets_*.csv"))
print(f"Found {len(files)} files.")

# üî∑ Create output file with header (only once)
first = True

for idx, file in enumerate(files):
    print(f"Processing {idx+1}/{len(files)}: {file}")

    # Load file
    df = pd.read_csv(file)

    # Add strain & timepoint from filename
    name_parts = file.replace(".csv", "").split("_")
    strain = name_parts[2]
    timepoint = name_parts[3]

    df['strain'] = strain
    df['timepoint'] = timepoint

    # Keep only needed columns
    if columns_to_keep:
        df = df[columns_to_keep]

    # Append to output
    df.to_csv(output_file, sep='\t', mode='a', index=False, header=first)
    first = False  # Only write header for first file

    # Free memory
    del df
    gc.collect()

print(f"\n‚úÖ Merged file saved as: {output_file}")

!gzip ceRNA_triplets_merged.csv

import pandas as pd

# üëá CHANGE THIS to the triplet file you want to process:
input_file = "ceRNA_triplets_H37Rv_1h.csv"
output_file = "ceRNA_triplets_H37Rv_1h_top10hubs.csv"

# Load the full triplet file
df = pd.read_csv(input_file)

print(f"Original file shape: {df.shape}")

# Count number of triplets per lncRNA (degree)
hub_counts = df['lncRNA'].value_counts().reset_index()
hub_counts.columns = ['lncRNA', 'count']

# Get top 10 hubs
top_hubs = hub_counts.head(10)['lncRNA'].tolist()
print(f"Top 10 hubs: {top_hubs}")

# Filter triplets where lncRNA is one of the top hubs
df_filtered = df[df['lncRNA'].isin(top_hubs)]

print(f"Filtered file shape: {df_filtered.shape}")

# Save filtered triplet file
df_filtered.to_csv(output_file, index=False)
print(f"Filtered triplet file saved as: {output_file}")

import pandas as pd

# Input and output
input_file = "ceRNA_triplets_H37Rv_1h.csv"
output_file = "ceRNA_triplets_H37Rv_1h_top10hubs.csv"

# Load full file
df = pd.read_csv(input_file)

print(f"Full file shape: {df.shape}")

# Count lncRNA hub degrees
hub_counts = df['lncRNA'].value_counts()
top10_hubs = hub_counts.head(10).index.tolist()

print("Top 10 hubs:", top10_hubs)

# Filter to rows where lncRNA is in top10
df_top10 = df[df['lncRNA'].isin(top10_hubs)]

print(f"Filtered file shape: {df_top10.shape}")

# Save
df_top10.to_csv(output_file, index=False)
print(f"Top 10 hub triplets saved: {output_file}")

import pandas as pd

# Define all timepoints and strains
timepoints = ["1h", "4h", "12h", "24h", "48h"]
strains = ["H37Rv", "H37Ra"]

for strain in strains:
    for tp in timepoints:
        print(f"üî∑ Processing: {strain} {tp}")

        # File paths
        triplet_file = f"ceRNA_triplets_{strain}_{tp}.csv"
        de_lnc_file = f"lncRNA_log2FC_{strain}_{tp}_filtered.csv"
        de_mrna_file = f"mRNA_log2FC_{strain}_{tp}_filtered.csv"
        output_file = f"ceRNA_triplets_{strain}_{tp}_with_log2FC.csv"

        # Load triplet
        df_triplet = pd.read_csv(triplet_file)

        # Load DE lncRNA & mRNA
        df_lnc = pd.read_csv(de_lnc_file)
        df_mrna = pd.read_csv(de_mrna_file)

        # Extract gene symbol from lncRNA Table.1
        df_lnc['lncRNA'] = df_lnc['Table.1'].apply(lambda x: x.split('-')[1] if '-' in x else x)
        df_mrna['mRNA'] = df_mrna['Table.1']

        df_lnc = df_lnc[['lncRNA', 'log2FC']]
        df_mrna = df_mrna[['mRNA', 'log2FC']]

        df_lnc.columns = ['lncRNA', 'lncRNA_log2FC']
        df_mrna.columns = ['mRNA', 'mRNA_log2FC']

        # Merge with triplet
        df_merged = df_triplet.merge(df_lnc, on='lncRNA', how='left')
        df_merged = df_merged.merge(df_mrna, on='mRNA', how='left')

        # Save
        df_merged.to_csv(output_file, index=False)
        print(f"‚úÖ Saved: {output_file} with shape {df_merged.shape}")

import pandas as pd
from pathlib import Path

# Directory with your files
folder = Path(".")

files = sorted(folder.glob("ceRNA_triplets_*_with_log2FC.csv"))

for file in files:
    print(f"üî∑ Processing {file.name}")
    df = pd.read_csv(file)

    # Count lncRNA frequency
    hub_counts = df['lncRNA'].value_counts().reset_index()
    hub_counts.columns = ['lncRNA', 'count']

    # Get top 10 hubs
    top_hubs = hub_counts.head(10)['lncRNA'].tolist()

    # Filter triplets for only top hubs
    df_top = df[df['lncRNA'].isin(top_hubs)]

    output = file.with_name(file.stem.replace("with_log2FC", "TOPHUBS") + ".csv")
    df_top.to_csv(output, index=False)
    print(f"‚úÖ Saved {output.name} with shape {df_top.shape}")

import pandas as pd
from pathlib import Path

# Folder where your files are
folder = Path(".")

# Get all files with this pattern
files = sorted(folder.glob("ceRNA_triplets_*_with_log2FC.csv"))

print(f"Found {len(files)} files")

for file in files:
    print(f"üî∑ Processing: {file.name}")

    # Read the file
    df = pd.read_csv(file)

    # Count lncRNA frequency
    hub_counts = df['lncRNA'].value_counts()
    top10_hubs = hub_counts.head(10).index.tolist()

    print(f"Top 10 hubs: {top10_hubs}")

    # Filter only rows with top10 lncRNAs
    df_top = df[df['lncRNA'].isin(top10_hubs)]

    # Save
    output = file.with_name(file.stem.replace("with_log2FC", "TOP10HUBS") + ".csv")
    df_top.to_csv(output, index=False)
    print(f"‚úÖ Saved: {output.name}  Shape: {df_top.shape}")

import pandas as pd

# Specify one file to process
input_file = "ceRNA_triplets_H37Rv_1h_with_log2FC.csv"
output_file = "ceRNA_triplets_H37Rv_1h_ONLY_TOP10HUBS.csv"

# Load the file
df = pd.read_csv(input_file)
print(f"‚úÖ Loaded: {input_file}  Shape: {df.shape}")

# Get top 10 most frequent lncRNAs
lncRNA_counts = df['lncRNA'].value_counts()
top10_lncRNAs = lncRNA_counts.head(10).index.tolist()
print(f"üî∑ Top 10 lncRNAs: {top10_lncRNAs}")

# Filter dataframe
df_top10 = df[df['lncRNA'].isin(top10_lncRNAs)].copy()
print(f"‚úÖ Filtered dataframe shape: {df_top10.shape}")
print(f"‚úÖ Unique lncRNAs in filtered: {df_top10['lncRNA'].nunique()}")
print(f"‚úÖ lncRNAs in filtered: {df_top10['lncRNA'].unique()}")

# Save filtered dataframe
df_top10.to_csv(output_file, index=False)
print(f"‚úÖ Saved filtered file: {output_file}")

import pandas as pd

# Input file (your single large file)
input_file = "ceRNA_triplets_H37Rv_1h_with_log2FC.csv"

# Output file: clear name
output_file = "ceRNA_triplets_H37Rv_1h_TOP10_FILTERED.csv"

# Load the full file
df = pd.read_csv(input_file)
print(f"‚úÖ Loaded: {input_file}  Shape: {df.shape}")

# Find top 10 lncRNAs by count
lncRNA_counts = df['lncRNA'].value_counts()
top10_lncRNAs = lncRNA_counts.head(10).index.tolist()
print(f"üî∑ Top 10 lncRNAs: {top10_lncRNAs}")

# Filter rows to keep only those 10 lncRNAs
df_top10 = df[df['lncRNA'].isin(top10_lncRNAs)].copy()

print(f"‚úÖ Filtered dataframe shape: {df_top10.shape}")
print(f"‚úÖ Unique lncRNAs in filtered file: {df_top10['lncRNA'].unique()}")

# Save only df_top10
df_top10.to_csv(output_file, index=False)
print(f"‚úÖ Filtered file saved as: {output_file}")

import pandas as pd

# Input and output
input_file = "ceRNA_triplets_H37Rv_1h_with_log2FC.csv"
output_file = "ceRNA_triplets_H37Rv_1h_TOP10_FILTERED_SMALL.csv"

# Read data
df = pd.read_csv(input_file)
print(f"‚úÖ Loaded: {input_file}  Shape: {df.shape}")

# Top 10 hubs
lncRNA_counts = df['lncRNA'].value_counts()
top10_lncRNAs = lncRNA_counts.head(10).index.tolist()
print(f"üî∑ Top 10 lncRNAs: {top10_lncRNAs}")

# Filter
df_top10 = df[df['lncRNA'].isin(top10_lncRNAs)].copy()
print(f"‚úÖ Rows after filtering to top 10 lncRNAs: {df_top10.shape}")

# For each hub, keep only first 100 rows
df_small = df_top10.groupby('lncRNA').head(100).reset_index(drop=True)

print(f"‚úÖ Final small file shape: {df_small.shape}")
print(f"‚úÖ Unique lncRNAs: {df_small['lncRNA'].unique()}")

# Save
df_small.to_csv(output_file, index=False)
print(f"‚úÖ Saved: {output_file}")

"""##filter for cytocsape"""

import pandas as pd
from pathlib import Path

# Directory
folder = Path(".")  # adjust if needed

# Find all *_with_log2FC.csv files
files = sorted(folder.glob("ceRNA_triplets_*_with_log2FC.csv"))

print(f"Found {len(files)} files.")

for file in files:
    print(f"\nüî∑ Processing: {file.name}")

    df = pd.read_csv(file)
    print(f"‚úÖ Loaded: {df.shape}")

    # Top 10 hubs
    lncRNA_counts = df['lncRNA'].value_counts()
    top10_lncRNAs = lncRNA_counts.head(10).index.tolist()
    print(f"üî∑ Top 10 lncRNAs: {top10_lncRNAs}")

    # Filter
    df_top10 = df[df['lncRNA'].isin(top10_lncRNAs)].copy()
    print(f"‚úÖ Rows after top 10 lncRNAs: {df_top10.shape}")

    # Cap at 100 triplets per hub
    df_small = df_top10.groupby('lncRNA').head(100).reset_index(drop=True)
    print(f"‚úÖ Final rows (capped): {df_small.shape}")

    # Save
    output_file = file.with_name(file.stem.replace("with_log2FC", "TOP10_FILTERED_SMALL") + ".csv")
    df_small.to_csv(output_file, index=False)
    print(f"‚úÖ Saved: {output_file.name}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy.cluster.hierarchy import linkage, dendrogram

# Folder
folder = Path(".")
files = sorted(folder.glob("*TOP10_FILTERED_SMALL.csv"))

print(f"Found {len(files)} files")

# Store hub sets
hub_sets = {}
labels = []

for file in files:
    df = pd.read_csv(file)
    hubs = set(df['lncRNA'].unique())
    hub_sets[file.stem] = hubs
    labels.append(file.stem)
    print(f"‚úÖ {file.stem}: {len(hubs)} unique hubs")

# Compute Jaccard index matrix
n = len(files)
jaccard_matrix = np.zeros((n, n))

for i in range(n):
    for j in range(n):
        set_i = hub_sets[labels[i]]
        set_j = hub_sets[labels[j]]
        intersection = len(set_i & set_j)
        union = len(set_i | set_j)
        jaccard_matrix[i, j] = intersection / union if union > 0 else 0

# Convert to DataFrame for nicer handling
jaccard_df = pd.DataFrame(jaccard_matrix, index=labels, columns=labels)

# Save matrix to CSV (optional)
jaccard_df.to_csv("Jaccard_index_matrix.csv")
print("‚úÖ Saved: Jaccard_index_matrix.csv")

# üî∑ Plot heatmap
plt.figure(figsize=(10,8), dpi=300)
sns.heatmap(jaccard_df, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'Jaccard similarity'})
plt.title("Jaccard similarity of lncRNA hubs (timepoints & strains)", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.savefig("Jaccard_heatmap.png", dpi=300)
plt.show()

# üî∑ Plot dendrogram
linked = linkage(1 - jaccard_matrix, method='ward')
plt.figure(figsize=(10,6), dpi=300)
dendrogram(linked, labels=labels, leaf_rotation=45)
plt.title("Dendrogram of lncRNA hub similarity (timepoints & strains)", fontsize=12)
plt.ylabel("Distance (1 - Jaccard)")
plt.tight_layout()
plt.savefig("Jaccard_dendrogram.png", dpi=300)
plt.show()

print("‚úÖ Plots saved: Jaccard_heatmap.png, Jaccard_dendrogram.png")

# replace full names with short names
short_names = {
    'ceRNA_triplets_H37Rv_1h_TOP10_FILTERED_SMALL': 'H37Rv_1h',
    'ceRNA_triplets_H37Rv_4h_TOP10_FILTERED_SMALL': 'H37Rv_4h',
    'ceRNA_triplets_H37Rv_12h_TOP10_FILTERED_SMALL': 'H37Rv_12h',
    'ceRNA_triplets_H37Rv_24h_TOP10_FILTERED_SMALL': 'H37Rv_24h',
    'ceRNA_triplets_H37Rv_48h_TOP10_FILTERED_SMALL': 'H37Rv_48h',
    'ceRNA_triplets_H37Ra_1h_TOP10_FILTERED_SMALL': 'H37Ra_1h',
    'ceRNA_triplets_H37Ra_4h_TOP10_FILTERED_SMALL': 'H37Ra_4h',
    'ceRNA_triplets_H37Ra_12h_TOP10_FILTERED_SMALL': 'H37Ra_12h',
    'ceRNA_triplets_H37Ra_24h_TOP10_FILTERED_SMALL': 'H37Ra_24h',
    'ceRNA_triplets_H37Ra_48h_TOP10_FILTERED_SMALL': 'H37Ra_48h'
}

# replace index & columns
jaccard_df.rename(index=short_names, columns=short_names, inplace=True)

# re-plot heatmap
plt.figure(figsize=(8,6))
sns.heatmap(jaccard_df, annot=True, cmap='YlGnBu', fmt=".2f")
plt.title("Jaccard similarity of lncRNA hubs")
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("jaccard_similarity_cleaned.png", dpi=300)
plt.show()

# re-plot dendrogram
plt.figure(figsize=(10,6))
dendrogram(linkage(1 - jaccard_df), labels=jaccard_df.index, leaf_rotation=45)
plt.title("Dendrogram of lncRNA hub similarity")
plt.ylabel("Distance (1 - Jaccard)")
plt.tight_layout()
plt.savefig("dendrogram_cleaned.png", dpi=300)
plt.show()

import pandas as pd
from pathlib import Path

folder = Path(".")  # adjust path if needed

files = sorted(folder.glob("*TOP10_FILTERED_SMALL.csv"))

records = []

for file in files:
    df = pd.read_csv(file)
    hubs = df['lncRNA'].unique()
    short_name = file.stem.replace("ceRNA_triplets_", "").replace("_TOP10_FILTERED_SMALL", "")
    for hub in hubs:
        records.append({"File": short_name, "lncRNA hub": hub})

# Convert to DataFrame
hubs_df = pd.DataFrame(records)

# Save
output_file = "lncRNA_hubs_per_file.csv"
hubs_df.to_csv(output_file, index=False)

print(f"‚úÖ Saved: {output_file}")

import pandas as pd

# Hard-coded MCC hub lists for all timepoints/strains
mcc_data = {
    "H37Ra_1h": ["CSNK1D", "MAN2C1", "LONP2", "MRPS25", "RPL30", "SGK1", "SLC35F5", "LTBP3", "PPP4C", "SFPQ"],
    "H37Ra_4h": ["CSNK1D", "UBP1", "MRPS25", "CLK1", "PHB2", "LTBP3", "SFPQ", "RPL30", "PPP4C", "SLC35F5"],
    "H37Ra_12h": ["CSNK1D", "UBP1", "SFPQ", "CLK1", "PHB2", "LTBP3", "MRPS25", "RPL30", "PPP4C", "SLC35F5"],
    "H37Ra_24h": ["CSNK1D", "MAN2C1", "LONP2", "MRPS25", "RPL30", "CTNNB1", "HUWE1", "CDKN1A", "CDK16", "CD44"],
    "H37Ra_48h": ["SFPQ", "RPL30", "CSNK1D", "BNIP2", "MRPS25", "LONP2", "LTBP3", "MKLN1", "PPP4C", "SLC35F5"],
    "H37Rv_1h": ["RPL30", "CSNK1D", "RNF146", "MRPS25", "ATXN3", "LTBP3", "SFPQ", "POMP", "ARID2", "SLC35F5"],
    "H37Rv_4h": ["CSNK1D", "UBP1", "SLC35F5", "LINC00273", "RPL30", "LONP2", "LTBP3", "SFPQ", "POMP", "PPP4C"],
    "H37Rv_12h": ["SFPQ", "CSNK1D", "RPL30", "UBP1", "BNIP2", "MRPS25", "LONP2", "SLC35F5", "POMP", "LTBP3"],
    "H37Rv_24h": ["SRRM2", "CSNK1D", "SGK1", "RPL30", "MRPS25", "LONP2", "SFPQ", "LTBP3", "PPP4C", "SLC35F5"],
    "H37Rv_48h": ["CSNK1D", "RPL30", "UBP1", "MRPS25", "CLK1", "LTBP3", "SFPQ", "EPC1", "SLC35F5", "PPP4C"]
}

# Create set of all unique hub genes
all_hubs = set()
for hubs in mcc_data.values():
    all_hubs.update(hubs)

# Build presence/absence matrix
matrix = pd.DataFrame(index=sorted(all_hubs))

for condition, hubs in mcc_data.items():
    matrix[condition] = matrix.index.isin(hubs).astype(int)

# Save to CSV
matrix_csv = "lncRNA_MCC_hub_presence_matrix.csv"
matrix.to_csv(matrix_csv)
print(f"‚úÖ Saved hub presence matrix: {matrix_csv}")

# Optional: save also as Excel
matrix_excel = "lncRNA_MCC_hub_presence_matrix.xlsx"
matrix.to_excel(matrix_excel)
print(f"‚úÖ Saved hub presence matrix: {matrix_excel}")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load matrix
df = pd.read_csv('/content/lncRNA_MCC_hub_presence_matrix.csv', index_col=0)

plt.figure(figsize=(12, 8))
sns.heatmap(df, cmap='Blues', linewidths=0.5, linecolor='gray', cbar=False)

plt.title('Presence/Absence of lncRNA MCC Hubs across Timepoints & Strains', fontsize=14)
plt.xlabel('Timepoint & Strain')
plt.ylabel('lncRNA Hubs')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig("lncRNA_MCC_hub_heatmap_plain.png", dpi=300)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load matrix
df = pd.read_csv('/content/lncRNA_MCC_hub_presence_matrix.csv', index_col=0)

# Clustered heatmap
g = sns.clustermap(df, cmap='Blues', linewidths=0.5, figsize=(12, 10), cbar=False)

plt.suptitle('Clustered Presence/Absence of lncRNA MCC Hubs', fontsize=14, y=1.02)
plt.savefig("lncRNA_MCC_hub_heatmap_clustered.png", dpi=300, bbox_inches='tight')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your file
file = "/content/lncRNA_MCC_hub_presence_matrix.csv"
df = pd.read_csv(file, index_col=0)

# Optional: reorder columns or rows if needed (otherwise skip this)
# df = df.sort_index(axis=0).sort_index(axis=1)

# Plot
plt.figure(figsize=(10, 8))  # Adjust figure size
sns.set(style="whitegrid")

ax = sns.heatmap(
    df,
    cmap=["#f0f0f0", "#2b83ba"],  # light gray for 0, blue for 1
    cbar=False,
    linewidths=0.5,
    linecolor="gray"
)

plt.title("Presence/Absence of lncRNA MCC Hubs Across Timepoints & Strains", fontsize=14)
plt.xlabel("Timepoint & Strain", fontsize=12)
plt.ylabel("lncRNA Hubs", fontsize=12)

plt.xticks(rotation=45, ha="right", fontsize=10)
plt.yticks(fontsize=10)

plt.tight_layout()
plt.savefig("lncRNA_MCC_hub_presence_clean_heatmap.png", dpi=300)
plt.show()

import pandas as pd

# Load your matrix
matrix = pd.read_csv('/content/lncRNA_MCC_hub_presence_matrix.csv', index_col=0)

# Get all genes present in at least one condition
present_genes = matrix.index[matrix.sum(axis=1) > 0].tolist()

# Save as txt for gseapy
with open("genes_for_enrichment.txt", "w") as f:
    for gene in present_genes:
        f.write(f"{gene}\n")

print(f"‚úÖ Saved clean gene list with {len(present_genes)} genes: genes_for_enrichment.txt")

import gseapy as gp

genes = present_genes  # from above script

enr = gp.enrichr(
    gene_list=genes,
    gene_sets=['GO_Biological_Process_2021'],
    organism='Human',
    outdir='enrichr_results',
    cutoff=0.05
)

results = enr.results
results.head(10)

from pathlib import Path
import pandas as pd
import gseapy as gp

# Define folder & files
folder = Path("/content")  # adjust if needed
files = sorted(folder.glob("ceRNA_triplets_*_TOP10_FILTERED_SMALL.csv"))

# Create output folders
(folder / "GO_Enrichment_lncRNA").mkdir(exist_ok=True)
(folder / "GO_Enrichment_mRNA").mkdir(exist_ok=True)

# Loop through files
for file in files:
    label = file.stem
    print(f"üî∑ Processing: {label}")

    # Read file
    df = pd.read_csv(file)

    # Extract unique lncRNAs & mRNAs
    lnc_genes = df['lncRNA'].dropna().unique().tolist()
    mRNA_genes = df['mRNA'].dropna().unique().tolist()

    # Run GO BP enrichment for lncRNAs
    enr_lnc = gp.enrichr(
        gene_list=lnc_genes,
        gene_sets='GO_Biological_Process_2021',
        organism='Human',
        outdir=f"GO_Enrichment_lncRNA/{label}",
        cutoff=0.05
    )
    print(f"‚úÖ lncRNA enrichment saved: GO_Enrichment_lncRNA/{label}")

    # Run GO BP enrichment for mRNAs
    enr_mRNA = gp.enrichr(
        gene_list=mRNA_genes,
        gene_sets='GO_Biological_Process_2021',
        organism='Human',
        outdir=f"GO_Enrichment_mRNA/{label}",
        cutoff=0.05
    )
    print(f"‚úÖ mRNA enrichment saved: GO_Enrichment_mRNA/{label}")

from pathlib import Path
import pandas as pd
import gseapy as gp

folder = Path("/content")
files = sorted(folder.glob("ceRNA_triplets_*_TOP10_FILTERED_SMALL.csv"))

(folder / "GO_Enrichment_lncRNA").mkdir(exist_ok=True)
(folder / "GO_Enrichment_mRNA").mkdir(exist_ok=True)

for file in files:
    label = file.stem
    print(f"üî∑ Processing: {label}")
    df = pd.read_csv(file)

    lnc_genes = df['lncRNA'].dropna().unique().tolist()
    mRNA_genes = df['mRNA'].dropna().unique().tolist()

    # lncRNAs
    try:
        enr_lnc = gp.enrichr(
            gene_list=lnc_genes,
            gene_sets='GO_Biological_Process_2021',
            organism='Human',
            outdir=f"GO_Enrichment_lncRNA/{label}",
            cutoff=None  # disable cutoff
        )
        print(f"‚úÖ lncRNA enrichment done: {label}")
    except Exception as e:
        print(f"‚ö†Ô∏è  No significant lncRNA enrichment for {label}: {e}")

    # mRNAs
    try:
        enr_mRNA = gp.enrichr(
            gene_list=mRNA_genes,
            gene_sets='GO_Biological_Process_2021',
            organism='Human',
            outdir=f"GO_Enrichment_mRNA/{label}",
            cutoff=None
        )
        print(f"‚úÖ mRNA enrichment done: {label}")
    except Exception as e:
        print(f"‚ö†Ô∏è  No significant mRNA enrichment for {label}: {e}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------
# üî∑ Choose which file to process
# -----------------------------
input_file = "/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv"  # üëà change here
save_prefix = "lncRNA_H37Ra"  # üëà change here

# -----------------------------
# üî∑ Read data
# -----------------------------
df = pd.read_csv(input_file)

print("‚úÖ Data Preview:")
print(df.head())

# -----------------------------
# üî∑ Prepare data for stacked barplot
# -----------------------------
bar_data = df.groupby(["Timepoint", "Regulation"]).size().reset_index(name="Count")

# Pivot for heatmap
heatmap_data = df.pivot_table(index="Gene", columns="Timepoint", values="Regulation", aggfunc="first")

# Map Regulation to numbers for heatmap: Up = 1, Down = -1, None = 0
heatmap_numeric = heatmap_data.replace({"Up": 1, "Down": -1})

# -----------------------------
# üî∑ Plot: Stacked Barplot
# -----------------------------
plt.figure(figsize=(8,6))
sns.barplot(
    data=bar_data,
    x="Timepoint", y="Count", hue="Regulation",
    palette={"Up": "tomato", "Down": "steelblue"}
)
plt.title(f"Up- and Down-regulated Genes over Time ({save_prefix})")
plt.ylabel("Number of Genes")
plt.xlabel("Timepoint")
plt.legend(title="Regulation")
plt.tight_layout()
plt.savefig(f"{save_prefix}_stacked_barplot.png", dpi=300)
plt.show()

# -----------------------------
# üî∑ Plot: Heatmap
# -----------------------------
plt.figure(figsize=(12,8))
sns.heatmap(
    heatmap_numeric,
    cmap=sns.color_palette(["steelblue", "white", "tomato"]),
    center=0,
    cbar_kws={'label': 'Regulation (Down=-1, Up=1)'}
)
plt.title(f"Gene Regulation Heatmap ({save_prefix})")
plt.ylabel("Gene")
plt.xlabel("Timepoint")
plt.tight_layout()
plt.savefig(f"{save_prefix}_heatmap.png", dpi=300)
plt.show()

print(f"‚úÖ Plots saved as: {save_prefix}_stacked_barplot.png and {save_prefix}_heatmap.png")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Paths to files
lncrna_file = "/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv"
mrna_file = "/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Ra.csv"

# Pick which one
file_to_use = lncrna_file  # üëà Change to mrna_file if needed
save_prefix = "lncRNA_H37Ra"  # üëà or mRNA_H37Ra

# Read data
df = pd.read_csv(file_to_use)

# Define timepoint order
timepoint_order = ["1h", "4h", "12h", "24h", "48h"]

# Aggregate
bar_data = (
    df.groupby(["Timepoint", "Regulation"])
    .size()
    .reset_index(name="Count")
    .pivot(index="Timepoint", columns="Regulation", values="Count")
    .reindex(timepoint_order)
    .fillna(0)
)

# Replace NaNs
bar_data = bar_data.fillna(0)

# Colors
colors = {"Up": "lightblue", "Down": "lightgray"}

# --------------
# Stacked Barplot
# --------------
bar_data.plot(
    kind="bar",
    stacked=True,
    color=[colors.get(c, "gray") for c in bar_data.columns],
    figsize=(8,6)
)
plt.title(f"Up- and Down-regulated Genes over Time ({save_prefix})")
plt.ylabel("Number of Genes")
plt.xlabel("Timepoint")
plt.xticks(rotation=0)
plt.legend(title="Regulation")
plt.tight_layout()
plt.savefig(f"{save_prefix}_stacked_barplot_sorted.png", dpi=300)
plt.show()

# ----------------------------------------
# Optional: Circular Barplot
# ----------------------------------------
fig = plt.figure(figsize=(8,8))
ax = plt.subplot(111, polar=True)

# Flatten data
bar_data_reset = bar_data.reset_index()
data_long = bar_data_reset.melt(id_vars="Timepoint", value_vars=["Up", "Down"], var_name="Regulation", value_name="Count")

# Create angles
N = len(data_long)
angles = np.linspace(0, 2 * np.pi, N, endpoint=False)

# Plot bars
bars = ax.bar(
    angles,
    data_long["Count"],
    color=data_long["Regulation"].map(colors),
    width=2*np.pi/N,
    alpha=0.8
)

ax.set_xticks(angles)
labels = [f"{row['Timepoint']}\n{row['Regulation']}" for idx, row in data_long.iterrows()]
ax.set_xticklabels(labels, fontsize=8)
plt.title(f"Circular Plot: Up & Down Regulation ({save_prefix})", y=1.1)

plt.tight_layout()
plt.savefig(f"{save_prefix}_circular_barplot.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

files = {
    'lncRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv',
    'lncRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Rv.csv',
    'mRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Ra.csv',
    'mRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Rv.csv'
}

timepoint_order = ['1h', '4h', '12h', '24h', '48h']

def load_and_count(filepath, strain):
    df = pd.read_csv(filepath)
    counts = (
        df.groupby(['Timepoint', 'Regulation'])
        .size()
        .reset_index(name='Count')
        .pivot(index='Timepoint', columns='Regulation', values='Count')
        .fillna(0)
        .astype(int)
    )
    counts['Strain'] = strain
    counts.reset_index(inplace=True)
    return counts

def plot_bar_and_circular(df_combined, out_prefix):
    df_combined['Timepoint'] = pd.Categorical(df_combined['Timepoint'], categories=timepoint_order, ordered=True)
    df_combined.sort_values(['Strain', 'Timepoint'], inplace=True)
    df_combined['Label'] = df_combined['Timepoint'].astype(str) + '_' + df_combined['Strain']

    # ================= BAR PLOT =================
    plt.figure(figsize=(10,6))
    x = np.arange(len(df_combined))
    width = 0.4
    plt.bar(x, df_combined['Down'], width, label='Down', color='lightgrey')
    plt.bar(x, df_combined['Up'], width, bottom=df_combined['Down'], label='Up', color='skyblue')
    plt.xticks(x, df_combined['Label'], rotation=45)
    plt.title(f"Up- and Down-regulated Genes over Time ({out_prefix})")
    plt.ylabel("Number of Genes")
    plt.xlabel("Timepoint & Strain")
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"barplot_up_down_{out_prefix}.png", dpi=300)
    plt.show()

    # ================= CIRCULAR PLOT =================
    labels = df_combined['Label']
    up_values = df_combined['Up'].values
    down_values = df_combined['Down'].values

    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False)
    fig, ax = plt.subplots(figsize=(10,10), subplot_kw={'projection':'polar'})
    bars_up = ax.bar(angles, up_values, width=0.3, color='skyblue', label='Up')
    bars_down = ax.bar(angles, down_values, width=0.3, bottom=up_values, color='lightgrey', label='Down')

    ax.set_xticks(angles)
    ax.set_xticklabels(labels, fontsize=8)
    plt.title(f"Circular Plot: Up & Down Regulation ({out_prefix})", pad=20)
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"circular_up_down_{out_prefix}.png", dpi=300)
    plt.show()

# ================= RUN FOR lncRNA =================
lnc_ra = load_and_count(files['lncRNA_H37Ra'], 'H37Ra')
lnc_rv = load_and_count(files['lncRNA_H37Rv'], 'H37Rv')
lnc_combined = pd.concat([lnc_ra, lnc_rv])
plot_bar_and_circular(lnc_combined, 'lncRNA')

# ================= RUN FOR mRNA =================
mrna_ra = load_and_count(files['mRNA_H37Ra'], 'H37Ra')
mrna_rv = load_and_count(files['mRNA_H37Rv'], 'H37Rv')
mrna_combined = pd.concat([mrna_ra, mrna_rv])
plot_bar_and_circular(mrna_combined, 'mRNA')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Paths
lnc_path = '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv'
lnc_rv_path = '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Rv.csv'
mrna_path = '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Ra.csv'
mrna_rv_path = '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Rv.csv'

# Function to process
def load_and_prepare(paths, label):
    dfs = []
    for path, strain in zip(paths, ['H37Ra', 'H37Rv']):
        df = pd.read_csv(path)
        df['Strain'] = strain
        dfs.append(df)
    combined = pd.concat(dfs)
    combined['Timepoint'] = pd.Categorical(combined['Timepoint'], categories=['1h', '4h', '12h', '24h', '48h'], ordered=True)
    return combined

lnc_df = load_and_prepare([lnc_path, lnc_rv_path], 'lncRNA')
mrna_df = load_and_prepare([mrna_path, mrna_rv_path], 'mRNA')

def plot_and_save(data, title, outname):
    plt.figure(figsize=(10,6))
    sns.set(style='white')
    sns.barplot(data=data, x='Timepoint', y='Gene', hue='Regulation', estimator=len, ci=None, palette=['lightgrey', 'lightblue'])
    plt.title(f'Up- and Down-regulated Genes over Time ({title})')
    plt.xlabel('Timepoint & Strain')
    plt.ylabel('Number of Genes')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(outname, dpi=300)
    plt.show()

plot_and_save(lnc_df, 'lncRNA', 'lncRNA_barplot_clean.png')
plot_and_save(mrna_df, 'mRNA', 'mRNA_barplot_clean.png')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

files = {
    'lncRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv',
    'lncRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Rv.csv',
    'mRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Ra.csv',
    'mRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Rv.csv'
}

timepoint_order = ['1h', '4h', '12h', '24h', '48h']

def load_and_count(filepath, strain):
    df = pd.read_csv(filepath)
    counts = (
        df.groupby(['Timepoint', 'Regulation'])
        .size()
        .reset_index(name='Count')
        .pivot(index='Timepoint', columns='Regulation', values='Count')
        .fillna(0)
        .astype(int)
    )
    counts['Strain'] = strain
    counts.reset_index(inplace=True)
    return counts

def plot_bar_and_circular(df_combined, out_prefix):
    df_combined['Timepoint'] = pd.Categorical(df_combined['Timepoint'], categories=timepoint_order, ordered=True)
    df_combined.sort_values(['Strain', 'Timepoint'], inplace=True)
    df_combined['Label'] = df_combined['Timepoint'].astype(str) + '_' + df_combined['Strain']

    # ================= BAR PLOT =================
    plt.figure(figsize=(10,6))
    x = np.arange(len(df_combined))
    width = 0.4

    plt.bar(x, df_combined['Down'], width, label='Down', color='lightgrey')
    plt.bar(x, df_combined['Up'], width, bottom=df_combined['Down'], label='Up', color='skyblue')

    plt.xticks(x, df_combined['Label'], rotation=45, ha='right')
    plt.title(f"Up- and Down-regulated Genes over Time ({out_prefix})")
    plt.ylabel("Number of Genes")
    plt.xlabel("Timepoint & Strain")
    plt.legend()
    plt.gca().set_facecolor('white')            # Remove grid background
    plt.grid(False)                             # Turn off grid
    plt.tight_layout()
    plt.savefig(f"barplot_up_down_{out_prefix}.png", dpi=300)
    plt.show()

    # ================= CIRCULAR PLOT =================
    labels = df_combined['Label']
    up_values = df_combined['Up'].values
    down_values = df_combined['Down'].values

    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False)
    fig, ax = plt.subplots(figsize=(10,10), subplot_kw={'projection':'polar'})

    bars_up = ax.bar(angles, up_values, width=0.3, color='skyblue', label='Up')
    bars_down = ax.bar(angles, down_values, width=0.3, bottom=up_values, color='lightgrey', label='Down')

    ax.set_xticks(angles)
    ax.set_xticklabels(labels, fontsize=8)
    plt.title(f"Circular Plot: Up & Down Regulation ({out_prefix})", pad=20)
    ax.set_facecolor('white')                   # Remove grid background
    ax.grid(False)                              # Turn off grid
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"circular_up_down_{out_prefix}.png", dpi=300)
    plt.show()

# ================= RUN FOR lncRNA =================
lnc_ra = load_and_count(files['lncRNA_H37Ra'], 'H37Ra')
lnc_rv = load_and_count(files['lncRNA_H37Rv'], 'H37Rv')
lnc_combined = pd.concat([lnc_ra, lnc_rv])
plot_bar_and_circular(lnc_combined, 'lncRNA')

# ================= RUN FOR mRNA =================
mrna_ra = load_and_count(files['mRNA_H37Ra'], 'H37Ra')
mrna_rv = load_and_count(files['mRNA_H37Rv'], 'H37Rv')
mrna_combined = pd.concat([mrna_ra, mrna_rv])
plot_bar_and_circular(mrna_combined, 'mRNA')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

files = {
    'lncRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Ra.csv',
    'lncRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_lncRNA_up_down_genes_H37Rv.csv',
    'mRNA_H37Ra': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Ra.csv',
    'mRNA_H37Rv': '/content/GO_Enrichment_mRNA/DE_mRNA_up_down_genes_H37Rv.csv'
}

timepoint_order = ['1h', '4h', '12h', '24h', '48h']

def load_and_count(filepath, strain):
    df = pd.read_csv(filepath)
    counts = (
        df.groupby(['Timepoint', 'Regulation'])
        .size()
        .reset_index(name='Count')
        .pivot(index='Timepoint', columns='Regulation', values='Count')
        .fillna(0)
        .astype(int)
    )
    counts['Strain'] = strain
    counts.reset_index(inplace=True)
    return counts

def plot_bar_and_circular(df_combined, out_prefix):
    df_combined['Timepoint'] = pd.Categorical(df_combined['Timepoint'], categories=timepoint_order, ordered=True)
    df_combined.sort_values(['Strain', 'Timepoint'], inplace=True)
    df_combined['Label'] = df_combined['Timepoint'].astype(str) + '_' + df_combined['Strain']

    # ================= BAR PLOT =================
    plt.figure(figsize=(10,6))
    x = np.arange(len(df_combined))
    width = 0.4

    plt.bar(x, df_combined['Down'], width, label='Down', color='lightgrey')
    plt.bar(x, df_combined['Up'], width, bottom=df_combined['Down'], label='Up', color='skyblue')

    plt.xticks(x, df_combined['Label'], rotation=45, ha='right')
    plt.title(f"Up- and Down-regulated Genes over Time ({out_prefix})")
    plt.ylabel("Number of Genes")
    plt.xlabel("Timepoint & Strain")
    plt.legend()
    plt.gca().set_facecolor('white')            # Remove grid background
    plt.grid(False)                             # Turn off grid
    plt.tight_layout()
    plt.savefig(f"barplot_up_down_{out_prefix}.png", dpi=300)
    plt.show()

    # ================= CIRCULAR PLOT =================
    labels = df_combined['Label']
    up_values = df_combined['Up'].values
    down_values = df_combined['Down'].values

    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False)
    fig, ax = plt.subplots(figsize=(10,10), subplot_kw={'projection':'polar'})

    bars_up = ax.bar(angles, up_values, width=0.3, color='skyblue', label='Up')
    bars_down = ax.bar(angles, down_values, width=0.3, bottom=up_values, color='lightgrey', label='Down')

    ax.set_xticks(angles)
    ax.set_xticklabels(labels, fontsize=8)
    plt.title(f"Circular Plot: Up & Down Regulation ({out_prefix})", pad=20)
    ax.set_facecolor('white')                   # Remove grid background
    ax.grid(False)                              # Turn off grid
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"circular_up_down_{out_prefix}.png", dpi=300)
    plt.show()

# ================= RUN FOR lncRNA =================
lnc_ra = load_and_count(files['lncRNA_H37Ra'], 'H37Ra')
lnc_rv = load_and_count(files['lncRNA_H37Rv'], 'H37Rv')
lnc_combined = pd.concat([lnc_ra, lnc_rv])
plot_bar_and_circular(lnc_combined, 'lncRNA')

# ================= RUN FOR mRNA =================
mrna_ra = load_and_count(files['mRNA_H37Ra'], 'H37Ra')
mrna_rv = load_and_count(files['mRNA_H37Rv'], 'H37Rv')
mrna_combined = pd.concat([mrna_ra, mrna_rv])
plot_bar_and_circular(mrna_combined, 'mRNA')

from google.colab import files
files.download("barplot_up_down_lncRNA.png")
files.download("circular_up_down_lncRNA.png")
files.download("barplot_up_down_mRNA.png")
files.download("circular_up_down_mRNA.png")

import os
print(os.listdir('/content'))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Your gene list
genes_of_interest = [
    'RPL30', 'CSNK1D', 'RNF146', 'MRPS25', 'ATXN3', 'LTBP3', 'SFPQ', 'POMP', 'ARID2',
    'SLC35F5', 'UBP1', 'LINC00273', 'LONP2', 'PPP4C', 'BNIP2', 'SRRM2', 'SGK1',
    'CLK1', 'EPC1', 'MAN2C1', 'PHB2', 'CTNNB1', 'HUWE1', 'CDKN1A', 'CDK16', 'CD44', 'MKLN1'
]

# Load GTEx v8 median TPM matrix
gtex_file = '/content/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz'
df = pd.read_csv(gtex_file, sep='\t', skiprows=2)

# Extract gene symbols
df['GeneSymbol'] = df['Description']

# Filter for your genes
df_genes = df[df['GeneSymbol'].isin(genes_of_interest)].copy()
df_genes.set_index('GeneSymbol', inplace=True)

# Drop metadata columns
df_genes = df_genes.drop(columns=['Name', 'Description'])

# Transpose so tissues are on x-axis, genes on y-axis
df_genes_T = df_genes.T

# Plot heatmap
plt.figure(figsize=(14,10))
sns.heatmap(df_genes_T, cmap='viridis')
plt.title('GTEx v8 Median Tissue Expression (TPM) of MCC Top Hub Genes')
plt.xlabel('Gene')
plt.ylabel('Tissue')
plt.tight_layout()
plt.savefig('GTEx_MCC_Hubs_Heatmap.png', dpi=300)
plt.show()

print("‚úÖ Heatmap saved: GTEx_MCC_Hubs_Heatmap.png")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Your gene list
genes_of_interest = [
    'RPL30', 'CSNK1D', 'RNF146', 'MRPS25', 'ATXN3', 'LTBP3', 'SFPQ', 'POMP', 'ARID2',
    'SLC35F5', 'UBP1', 'LINC00273', 'LONP2', 'PPP4C', 'BNIP2', 'SRRM2', 'SGK1',
    'CLK1', 'EPC1', 'MAN2C1', 'PHB2', 'CTNNB1', 'HUWE1', 'CDKN1A', 'CDK16', 'CD44', 'MKLN1'
]

# Select only relevant tissues
relevant_tissues = [
    'Lung',
    'Whole Blood',
    'Spleen',
    'Cells - EBV-transformed lymphocytes',
    'Cells - Cultured fibroblasts',
    'Skin - Not Sun Exposed (Suprapubic)',
    'Skin - Sun Exposed (Lower leg)',
    'Liver',
    'Adipose - Subcutaneous',
    'Adipose - Visceral (Omentum)'
]

# Load GTEx v8 median TPM matrix
gtex_file = '/content/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz'
df = pd.read_csv(gtex_file, sep='\t', skiprows=2)

# Extract gene symbols
df['GeneSymbol'] = df['Description']

# Filter for your genes
df_genes = df[df['GeneSymbol'].isin(genes_of_interest)].copy()
df_genes.set_index('GeneSymbol', inplace=True)

# Drop metadata columns
df_genes = df_genes.drop(columns=['Name', 'Description'])

# Transpose so tissues are on x-axis, genes on y-axis
df_genes_T = df_genes.T

# Keep only relevant tissues
df_relevant = df_genes_T[df_genes_T.index.isin(relevant_tissues)]

# Plot heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(df_relevant, cmap='viridis')
plt.title('GTEx v8 Median Tissue Expression (TPM) of MCC Top Hub Genes (Selected Tissues)')
plt.xlabel('Gene')
plt.ylabel('Tissue')
plt.tight_layout()
plt.savefig('GTEx_MCC_Hubs_Heatmap_SelectedTissues.png', dpi=300)
plt.show()

print("‚úÖ Heatmap saved: GTEx_MCC_Hubs_Heatmap_SelectedTissues.png")

!pip install scanpy

# Install Scanpy
!pip install scanpy

import scanpy as sc
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

# Path to your uploaded h5ad file
h5ad_path = "/content/GTEx_8_tissues_snRNAseq_immune_atlas_071421.public_obs.h5ad"

# Your MCC gene list
mcc_genes = [
    'RPL30', 'CSNK1D', 'RNF146', 'MRPS25', 'ATXN3', 'LTBP3', 'SFPQ', 'POMP', 'ARID2',
    'SLC35F5', 'UBP1', 'LINC00273', 'LONP2', 'PPP4C', 'BNIP2', 'SRRM2', 'SGK1', 'CLK1',
    'EPC1', 'MAN2C1', 'PHB2', 'CTNNB1', 'HUWE1', 'CDKN1A', 'CDK16', 'CD44', 'MKLN1'
]

# ‚úÖ Load data
adata = sc.read_h5ad(h5ad_path)
print(f"‚úÖ Loaded single-cell data: {adata.shape}")

print("Cell metadata columns:", list(adata.obs.columns))

# ‚úÖ Find which MCC genes are present
present_genes = [g for g in mcc_genes if g in adata.var_names]
missing_genes = [g for g in mcc_genes if g not in adata.var_names]
print(f"‚úÖ Genes found: {len(present_genes)} -> {present_genes}")
if missing_genes:
    print(f"‚ö†Ô∏è Missing genes: {missing_genes}")

# ‚úÖ Choose cell type annotation
if 'annotation' in adata.obs.columns:
    groupby = 'annotation'
elif 'broad' in adata.obs.columns:
    groupby = 'broad'
elif 'granular' in adata.obs.columns:
    groupby = 'granular'
else:
    raise ValueError(f"‚ùå No suitable cell type column found. Columns available: {adata.obs.columns.tolist()}")

print(f"‚úÖ Using cell type grouping: {groupby}")

# ‚úÖ Dotplot
sc.pl.dotplot(
    adata,
    var_names=present_genes,
    groupby=groupby,
    standard_scale='var',
    figsize=(14,6),
    save="_GTEx_MCC_Hubs_Dotplot.png"  # Will be saved in `figures/`
)

print("‚úÖ Dotplot saved in: `figures/dotplot_GTEx_MCC_Hubs_Dotplot.png`")

"""##Enrichment from rummaging"""

import pandas as pd

# Path to the uploaded file
file_path = '/content/61daatset_mtb_rummaging .xlsx'

# Read the Excel file
df = pd.read_excel(file_path)

# Display shape & columns
print(f"‚úÖ File loaded: {df.shape[0]} rows √ó {df.shape[1]} columns")
print("\nüìÑ Columns:")
print(df.columns.tolist())

# Show first few rows
df.head()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Path
file_path = '/content/61daatset_mtb_rummaging .xlsx'

df = pd.read_excel(file_path)

print(f"Loaded: {df.shape[0]} rows √ó {df.shape[1]} cols")

# Filter
df_sig = df[(df['adjPValue'] < 0.05) & (df['overlap'] >= 2)].copy()
df_sig.sort_values('adjPValue', inplace=True)

print(f"Significant: {df_sig.shape[0]} rows")

df_sig.head(3)

df_sig.to_csv('/content/MTB_rummaging_significant.csv', index=False)
print("‚úÖ Saved filtered results: MTB_rummaging_significant.csv")

top_n = 15
df_plot = df_sig.head(top_n)

plt.figure(figsize=(10,6))
sns.barplot(
    y=df_plot['condition1Title'] + '\nvs\n' + df_plot['condition2Title'],
    x=-df_plot['adjPValue'].apply(lambda x: -np.log10(x)),
    hue=df_plot['direction'],
    dodge=False,
    palette={'up':'red', 'dn':'blue'}
)

plt.xlabel('-log10(adjPValue)')
plt.ylabel('Comparison')
plt.title('Top MTB-related Gene Sets (Rummaging)')
plt.legend(title='Direction')
plt.tight_layout()
plt.savefig('/content/MTB_rummaging_top15_barplot.png', dpi=300)
plt.show()

print("‚úÖ Saved: MTB_rummaging_top15_barplot.png")

import numpy as np  # ‚úÖ ADD THIS!

top_n = 15
df_plot = df_sig.head(top_n).copy()

plt.figure(figsize=(10, 6))

# Combine condition1 and condition2 as labels
df_plot['Comparison'] = df_plot['condition1Title'] + '\nvs\n' + df_plot['condition2Title']

sns.barplot(
    y='Comparison',
    x=df_plot['adjPValue'].apply(lambda x: -np.log10(x)),
    hue='direction',
    data=df_plot,
    dodge=False,
    palette={'up': 'red', 'dn': 'blue'}
)

plt.xlabel(r'$-\log_{10}$(adjPValue)')
plt.ylabel('Comparison')
plt.title('Top MTB-related Gene Sets (Rummaging)')
plt.legend(title='Direction')
plt.tight_layout()
plt.savefig('/content/MTB_rummaging_top15_barplot.png', dpi=300)
plt.show()

print("‚úÖ Saved: MTB_rummaging_top15_barplot.png")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ‚úÖ Load filtered significant data
df = pd.read_csv('/content/MTB_rummaging_significant.csv')

# üî∑ Select top N (optional) ‚Äî here top 20 most significant
df = df.sort_values('adjPValue').head(20)

# üî∑ Clean up labels: make shorter & readable
def shorten(text, length=50):
    if len(text) > length:
        return text[:length] + '...'
    else:
        return text

df['Comparison'] = df['condition1Title'].apply(shorten) + ' vs ' + df['condition2Title'].apply(shorten)

# üî∑ Create a column for -log10(adjPValue)
df['-log10(adjPValue)'] = -np.log10(df['adjPValue'])

# üî∑ Plot
plt.figure(figsize=(10,8))
sns.barplot(
    data=df,
    x='-log10(adjPValue)',
    y='Comparison',
    hue='direction',
    dodge=False,
    palette={'up':'red', 'dn':'blue'}
)

plt.title("Top MTB-related Gene Sets (Rummaging, filtered)")
plt.xlabel("-log10(adjPValue)")
plt.ylabel("Comparison")

plt.legend(title='Direction', loc='lower right')
plt.tight_layout()

# ‚úÖ Save high-quality figure
plt.savefig("MTB_rummaging_barplot_clean.png", dpi=300)
plt.show()
print("‚úÖ Saved: MTB_rummaging_barplot_clean.png")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the file
df = pd.read_csv("/content/MTB_rummaging_significant.csv")

# Apply additional filters
df_filtered = df[
    (df['adjPValue'] <= 0.01) &
    (df['oddsRatio'] >= 3)
].copy()

print(f"‚úÖ Filtered: {df_filtered.shape[0]} rows")

# Create a simpler table
df_filtered_table = df_filtered[[
    'condition1Title', 'condition2Title', 'direction',
    'overlap', 'oddsRatio', 'adjPValue'
]].sort_values('adjPValue')

df_filtered_table.to_csv("MTB_rummaging_filtered_table.csv", index=False)
print("üìÑ Saved: MTB_rummaging_filtered_table.csv")

# For plotting: combine condition names
df_filtered['comparison'] = df_filtered['condition1Title'] + "\nvs\n" + df_filtered['condition2Title']
df_filtered['log_adjP'] = -np.log10(df_filtered['adjPValue'])

# Shorten to top N
top_n = 20
df_plot = df_filtered.nsmallest(top_n, 'adjPValue')

plt.figure(figsize=(8, max(6, top_n/2)))
sns.scatterplot(
    y='comparison', x='log_adjP', hue='direction',
    data=df_plot, palette={'up':'red', 'dn':'blue'}, s=100
)

plt.title("Top MTB-related Gene Sets (Filtered)")
plt.xlabel("-log10(adjPValue)")
plt.ylabel("Comparison")
plt.tight_layout()
plt.savefig("MTB_rummaging_filtered_plot.png", dpi=300)
plt.show()

print("üìä Saved: MTB_rummaging_filtered_plot.png")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load filtered data
df_filtered = pd.read_csv("/content/MTB_rummaging_filtered_table.csv")

# Sort by adjPValue and keep top 20
df_plot = df_filtered.nsmallest(20, 'adjPValue').copy()
df_plot['log_adjP'] = -np.log10(df_plot['adjPValue'])

# Add an ID column
df_plot['ID'] = [f"C{i+1}" for i in range(len(df_plot))]

# Save a legend table
legend_table = df_plot[['ID', 'condition1Title', 'condition2Title', 'direction', 'adjPValue', 'oddsRatio']]
legend_table.to_csv("MTB_rummaging_legend_table.csv", index=False)

# Make plot
plt.figure(figsize=(10, 12))
sns.scatterplot(
    x='log_adjP',
    y='ID',
    hue='direction',
    data=df_plot,
    palette={'up': 'red', 'dn': 'blue'},
    s=100
)

plt.title("Top MTB-related Gene Sets (Filtered, with IDs)")
plt.xlabel("-log10(adjPValue)")
plt.ylabel("Comparison ID")
plt.tight_layout()
plt.savefig("MTB_rummaging_filtered_plot_with_IDs.png", dpi=300)
plt.show()

print("‚úÖ Saved: MTB_rummaging_filtered_plot_with_IDs.png")
print("üìÑ Legend Table: MTB_rummaging_legend_table.csv")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load filtered data
df_filtered = pd.read_csv("/content/MTB_rummaging_filtered_table.csv")

# Sort by adjPValue and keep top 20
df_plot = df_filtered.nsmallest(20, 'adjPValue').copy()
df_plot['log_adjP'] = -np.log10(df_plot['adjPValue'])

# Add an ID column
df_plot['ID'] = [f"C{i+1}" for i in range(len(df_plot))]

# Save a legend table
legend_table = df_plot[['ID', 'condition1Title', 'condition2Title', 'direction', 'adjPValue', 'oddsRatio']]
legend_table.to_csv("MTB_rummaging_legend_table.csv", index=False)

# Make plot
plt.figure(figsize=(10, 12))
sns.scatterplot(
    x='log_adjP',
    y='ID',
    hue='direction',
    data=df_plot,
    palette={'up': 'red', 'dn': 'blue'},
    s=100
)

plt.title("Top MTB-related Gene Sets (Filtered, with IDs)")
plt.xlabel("-log10(adjPValue)")
plt.ylabel("Comparison ID")
plt.tight_layout()
plt.savefig("MTB_rummaging_filtered_plot_with_IDs.png", dpi=300)
plt.show()

print("‚úÖ Saved: MTB_rummaging_filtered_plot_with_IDs.png")
print("üìÑ Legend Table: MTB_rummaging_legend_table.csv")

import pandas as pd

# ‚úÖ Load rummaging significant results
rummaging_df = pd.read_csv('/content/MTB_rummaging_significant.csv')

# ‚úÖ Load your MCC genes (should be one column, e.g., 'Gene')
mcc_genes_df = pd.read_csv('/content/mcc_genes.csv')  # Upload this file!
mcc_genes = set(mcc_genes_df.iloc[:, 0].str.upper().unique())

# ‚úÖ Extract gene sets from the rummaging tool (assume each gene set is already known)
# If you have a list of genes per row, include that in the original file.
# Otherwise, you must fetch gene sets per GSE manually (or from Rummagene API if available).

# For now, let's assume you've added a column `geneList` in the CSV
# where each cell contains comma-separated genes (like: 'CDKN1A,HUWE1,SGK1')

# üîç Calculate overlap with MCC genes
def find_mcc_overlap(gene_list_str):
    genes = set(gene_list_str.upper().split(','))
    overlap_genes = mcc_genes.intersection(genes)
    return pd.Series({
        'MCC_genes_found': ', '.join(overlap_genes),
        'MCC_overlap_count': len(overlap_genes)
    })

# Apply to the dataset
if 'geneList' in rummaging_df.columns:
    overlap_info = rummaging_df['geneList'].apply(find_mcc_overlap)
    final_df = pd.concat([rummaging_df, overlap_info], axis=1)

    # Save result
    final_df.to_csv('/content/MCC_GeneOverlap_with_RummagingTable.csv', index=False)
    print("‚úÖ File saved as MCC_GeneOverlap_with_RummagingTable.csv")
else:
    print("‚ùå Column 'geneList' not found in the file. Please add the gene sets for each row.")

import pandas as pd
import numpy as np

# Load data
df = pd.read_csv("MTB_rummaging_significant.csv")

# Clean and convert columns if needed
df['Adj. PValue'] = pd.to_numeric(df['Adj. PValue'], errors='coerce')
df['Overlap'] = pd.to_numeric(df['Overlap'], errors='coerce')
df['Odds'] = pd.to_numeric(df['Odds'], errors='coerce')
df['Silhouette Score'] = pd.to_numeric(df['Silhouette Score'], errors='coerce')

# Composite score: high overlap, odds; low adj.PValue; strong silhouette (absolute)
df['Score'] = (
    -np.log10(df['Adj. PValue']) +
    df['Overlap'] +
    df['Odds'] +
    df['Silhouette Score'].abs()
)

# Sort and select top 5
top5 = df.sort_values(by='Score', ascending=False).head(5)

# Show selected genes and important columns
print(top5[['Title', 'Adj. PValue', 'Overlap', 'Odds', 'Silhouette Score', 'Score']])

# üì¶ Required packages
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# üìÇ Upload file
from google.colab import files
uploaded = files.upload()

# üì• Load Excel file
df = pd.read_excel("MTB_rummaging_significant_final.xlsx")

# ‚úÖ Filter top entries using strong criteria
filtered = df[
    (df['Silhouette Score'] >= 0.5) &
    (df['overlap'] >= 3) &
    (df['adjPValue'] <= 0.01) &
    (df['oddsRatio'] >= 5)
].copy()

# üéØ Sort to get Top 10 entries
top_hits = filtered.sort_values(
    by=['overlap', 'Silhouette Score', 'adjPValue'],
    ascending=[False, False, True]
).head(10)

# ‚úÖ Display summary
top_hits_display = top_hits[['gse', 'condition1Title', 'condition2Title', 'direction', 'overlap', 'Silhouette Score', 'adjPValue']]
print("üìä Top 10 MTB-related transcriptomic matches:")
display(top_hits_display)

# üìà Visualization ‚Äì Clear horizontal bar plot
plt.figure(figsize=(12, 7))
plot_labels = top_hits['condition1Title'] + "\nvs\n" + top_hits['condition2Title']
sns.barplot(
    y=plot_labels,
    x=top_hits['overlap'],
    hue=top_hits['direction'],
    palette="Set2",
    dodge=False
)
plt.xlabel("Gene Overlap with MCC Genes")
plt.ylabel("Comparison Conditions")
plt.title("Top 10 MTB-related Transcriptomic Signatures (Filtered & Ranked)")
plt.tight_layout()
plt.grid(True, axis='x', linestyle='--', alpha=0.5)
plt.savefig("Top10_MTB_Signatures_Barplot.png", dpi=300)
plt.show()

# üî¢ Create short names
top_hits['short_label'] = ['C'+str(i+1) for i in range(len(top_hits))]

# üîÄ Create mapping dictionary for caption/legend
label_map = dict(zip(top_hits['short_label'], top_hits['condition1Title'] + ' vs ' + top_hits['condition2Title']))

# üìà Plot with short labels
plt.figure(figsize=(10, 6))
sns.barplot(
    y=top_hits['short_label'],
    x=top_hits['overlap'],
    hue=top_hits['direction'],
    dodge=False,
    palette="Set2"
)
plt.xlabel("Gene Overlap with MCC Genes")
plt.ylabel("Condition Comparison (Short Labels)")
plt.title("Top 10 Transcriptomic Matches (Simplified)")
plt.grid(True, axis='x', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig("Top10_MTB_Simplified.png", dpi=300)
plt.show()

# üìò Print legend
print("üßæ Condition Label Mapping:")
for k, v in label_map.items():
    print(f"{k}: {v}")

import plotly.express as px

fig = px.bar(
    top_hits,
    x='overlap',
    y='condition1Title',
    color='direction',
    hover_data=['condition2Title', 'adjPValue', 'Silhouette Score'],
    orientation='h',
    title='Top 10 MTB Transcriptomic Comparisons'
)
fig.update_layout(yaxis_title="Condition 1", xaxis_title="Overlap with MCC Genes")
fig.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load your Excel file
file_path = '/content/MTB_rummaging_significant_final.xlsx'  # Update if needed
df = pd.read_excel(file_path)

# Step 2: Sort by 'Silhouette Score' and 'overlap'
df_top = df.sort_values(by=['Silhouette Score', 'overlap'], ascending=[False, False]).head(10)

# Step 3: Plot
plt.figure(figsize=(10, 6))
sns.set(style='whitegrid')
palette = {'up': '#5DAF83', 'dn': '#EF7763'}

bar = sns.barplot(
    data=df_top,
    y='condition1Title',
    x='overlap',
    hue='direction',
    palette=palette
)

plt.xlabel('Gene Overlap with MCC Genes')
plt.ylabel('Comparison Conditions')
plt.title('Top 10 MTB Transcriptomic Comparisons')
plt.legend(title='direction', loc='lower right')
plt.tight_layout()

# Step 4: Save figure (300 DPI) and filtered CSV
plt.savefig("Top10_MTB_Transcriptomic_Matches_300DPI.png", dpi=300)
df_top.to_csv("Top10_MTB_Transcriptomic_Matches.csv", index=False)

plt.show()

plt.figure(figsize=(10, 6))
sorted_df = df_top.sort_values(by='overlap', ascending=True)
colors = sorted_df['direction'].map({'up': '#5DAF83', 'dn': '#EF7763'})

plt.hlines(y=sorted_df['condition1Title'], xmin=0, xmax=sorted_df['overlap'], color=colors)
plt.plot(sorted_df['overlap'], sorted_df['condition1Title'], "o", color='black')
for i, val in enumerate(sorted_df['overlap']):
    plt.text(val + 0.2, i, str(val), va='center', fontsize=9)

plt.xlabel('Gene Overlap with MCC Genes')
plt.ylabel('Comparison Conditions')
plt.title('Top 10 Transcriptomic Matches (Lollipop Plot)')
plt.tight_layout()
plt.savefig("Top10_MTB_Lollipop_300DPI.png", dpi=300)
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=sorted_df,
    x='overlap',
    y='condition1Title',
    size='Silhouette Score',
    hue='direction',
    sizes=(50, 300),
    palette={'up': '#5DAF83', 'dn': '#EF7763'}
)
plt.xlabel("Overlap with MCC Genes")
plt.ylabel("Comparison Conditions")
plt.title("Transcriptomic Matches: Dot Size = Silhouette Score")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.savefig("Top10_MTB_DotPlot_300DPI.png", dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your data (replace with actual path if needed)
df = pd.read_excel('/content/MTB_rummaging_significant_final.xlsx')

# Sort by 'Overlap' and select top 10
df_top10 = df.sort_values(by='Overlap', ascending=False).head(10).copy()

# Create short labels (C1 to C10)
df_top10['Short_Label'] = ['C' + str(i+1) for i in range(len(df_top10))]

# Save the simplified mapping to CSV
df_top10[['Short_Label', 'Condition 1', 'Condition 2', 'Overlap', 'direction']].to_csv(
    'Simplified_Top10_Transcriptomic_Comparisons.csv', index=False
)

# Set seaborn style
sns.set(style="whitegrid")

# Create barplot
plt.figure(figsize=(10, 6))
sns.barplot(
    data=df_top10,
    y='Short_Label',
    x='Overlap',
    hue='direction',
    palette={'up': '#69b3a2', 'dn': '#e76f51'}
)

# Customize plot
plt.title('Top 10 Transcriptomic Matches (Simplified)', fontsize=14)
plt.xlabel('Gene Overlap with MCC Genes', fontsize=12)
plt.ylabel('Condition Comparison (Short Labels)', fontsize=12)
plt.legend(title='direction')
plt.tight_layout()

# Save high-resolution image
plt.savefig('Simplified_Top10_Transcriptomic_Comparisons_300dpi.png', dpi=300)

# Show plot
plt.show()

# Load the Excel file
import pandas as pd

df = pd.read_excel('/content/MTB_rummaging_significant_final.xlsx')

# Show all column names
print(df.columns.tolist())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load your data
df = pd.read_excel('/content/MTB_rummaging_significant_final.xlsx')

# Step 2: Sort by 'overlap' and get top 10
df_top10 = df.sort_values(by='overlap', ascending=False).head(10).copy()

# Step 3: Assign short labels for readability
df_top10['Short_Label'] = ['C'+str(i+1) for i in range(len(df_top10))]

# Step 4: Plot
plt.figure(figsize=(10, 6))
sns.barplot(data=df_top10, x='overlap', y='Short_Label', hue='direction', palette={'up':'mediumseagreen', 'dn':'lightsalmon'})
plt.xlabel('Gene Overlap with MCC Genes')
plt.ylabel('Condition Comparison (Short Labels)')
plt.title('Top 10 Transcriptomic Matches (Simplified)')
plt.legend(title='direction')
plt.tight_layout()

# Step 5: Save high-resolution image
plt.savefig("top10_transcriptomic_matches.png", dpi=300)

# Step 6: Save top 10 CSV
df_top10.to_csv("top10_transcriptomic_matches.csv", index=False)

import pandas as pd

# Step 1: Load GO enrichment CSV file (update path if needed)
file_path = '/content/GENE_ONTOLOGY.csv'  # Update if your file is elsewhere
df = pd.read_csv(file_path)

# Step 2: Filter by adjusted p-value
df_filtered = df[df['Adjusted P-value'] < 0.05]

# Step 3: Define extended biological keywords
keywords = [
   'immune system', 'host response', 'immune signaling', 'macrophage activation',
             'granuloma', 'phagosome', 'IL-1', 'IL-6', 'IL-10', 'TNF-alpha', 'IFN-gamma',
             'lung epithelial', 'chemokine', 'pattern recognition receptor', 'TLR', 'NOD2']


# Step 4: Search for GO terms containing any keyword
df_matched = df_filtered[df_filtered['Term'].str.contains('|'.join(keywords), case=False, na=False)]

# Step 5: If no match, return top 20 enriched terms by combined score
if df_matched.empty:
    print("‚ö†Ô∏è No enriched GO terms matched the keyword list.")
    df_result = df_filtered.sort_values(by='Combined Score', ascending=False).head(20)
else:
    df_result = df_matched.sort_values(by='Combined Score', ascending=False).head(20)

# Step 6: Display results
print("\nüéØ Final Filtered Results:")
display(df_result[['Term', 'Overlap', 'Adjusted P-value', 'Odds Ratio', 'Combined Score', 'Genes']])

# Step 7: Save output CSV
output_path = '/content/Filtered_GO_Results.csv'
df_result.to_csv(output_path, index=False)
print(f"\n‚úÖ Results saved to: {output_path}")

import pandas as pd

# Step 1: Load the GO enrichment file
file_path = '/content/GENE_ONTOLOGY.csv'  # Update if your file path differs
df = pd.read_csv(file_path)

# Step 2: Filter for statistically significant terms
df_filtered = df[df['Adjusted P-value'] < 0.05]

# Step 3: Define keyword list relevant to TB, immunity, apoptosis, etc.
keywords = [
    'immune', 'inflammatory', 'cytokine', 'apoptosis', 'autophagy',
    'infection', 'host', 'response', 'interferon', 'TNF', 'NF-kB', 'defense',
    'macrophage', 'phagosome', 'granuloma', 'oxidative', 'stress',
    'DNA repair', 'cell death', 'Wnt', 'TGF-beta', 'signal transduction',
    'lung', 'tuberculosis', 'mycobacterium tuberculosis', 'type I interferon',
    'IL-1', 'IL-6', 'IFNG', 'chemokine', 'necrosis', 'JAK-STAT', 'MAPK',
    'NFkB', 'pattern recognition', 'apoptotic process', 'regulation of apoptosis'
]

# Step 4: Filter based on keyword match
pattern = '|'.join(keywords)
df_matched = df_filtered[df_filtered['Term'].str.contains(pattern, case=False, na=False)]

# Step 5: Define functional categories
def categorize_term(term):
    term_lower = term.lower()
    if any(k in term_lower for k in ['apoptosis', 'cell death', 'necrosis']):
        return 'Cell Death / Apoptosis'
    elif any(k in term_lower for k in ['immune', 'inflammatory', 'cytokine', 'host', 'defense', 'interferon', 'macrophage', 'pathogen']):
        return 'Immune / Host Response'
    elif any(k in term_lower for k in ['repair', 'dna damage', 'homologous recombination']):
        return 'DNA Repair / Genomic Stability'
    elif any(k in term_lower for k in ['wnt', 'tgf-beta', 'jak-stat', 'signal transduction', 'mapk', 'nfb']):
        return 'Signal Transduction'
    elif any(k in term_lower for k in ['oxidative', 'stress']):
        return 'Stress Response'
    elif any(k in term_lower for k in ['lung', 'tuberculosis', 'mycobacterium']):
        return 'TB / Tissue-Specific'
    else:
        return 'Other / Non-specific'

# Step 6: Apply categorization
df_matched['Category'] = df_matched['Term'].apply(categorize_term)

# Step 7: Sort by Combined Score
df_final = df_matched.sort_values(by='Combined Score', ascending=False).reset_index(drop=True)

# Step 8: Display final table
print("‚úÖ Final Categorized GO Enrichment Terms:\n")
display(df_final[['Term', 'Category', 'Adjusted P-value', 'Combined Score', 'Genes']])

# Step 9: Save final results
output_path = '/content/Filtered_Categorized_GO_Results.csv'
df_final.to_csv(output_path, index=False)
print(f"\nüìÅ Final results saved to: {output_path}")

import pandas as pd

# Load the GO_BIO.csv file
df = pd.read_csv('/content/GO_BIO.csv')  # Update this path if needed

# Convert all relevant text columns to lowercase for case-insensitive matching
df['Term'] = df['Term'].astype(str).str.lower()

# Define GO-related biological keywords (lowercase for matching)
keywords = [
    "regulation of apoptotic process",
    "negative regulation of apoptotic process",
    "negative regulation of programmed cell death",
    "double-strand break repair",
    "regulation of dna repair",
    "regulation of double-strand break repair via homologous recombination",
    "recombinational repair",
    "positive regulation of double-strand break repair",
    "positive regulation of canonical wnt signaling pathway",
    "regulation of humoral immune response",
    "regulation of immune effector process",
    "negative regulation of intrinsic apoptotic signaling pathway by p53 class mediator",
    "regulation of intrinsic apoptotic signaling pathway in response to dna damage by p53 class mediator",
    "positive regulation of erk1 and erk2 cascade",
    "regulation of complement activation",
    "regulation of oxidative stress-induced intrinsic apoptotic signaling pathway",
    "negative regulation of intrinsic apoptotic signaling pathway in response to dna damage",
    "regulation of programmed cell death",
    "cytoplasmic pattern recognition receptor signaling pathway",
    "regulation of canonical wnt signaling pathway",
    "positive regulation of intrinsic apoptotic signaling pathway",
    "regulation of dna damage response, signal transduction by p53 class mediator",
    "positive regulation of production of molecular mediator of immune response",
    "base-excision repair",
    "chromatin remodeling",
    "dna repair",
    "positive regulation of dna repair",
    "mitophagy",
    "autophagy of mitochondrion",
    "positive regulation of t cell activation",
    "t cell activation",
    "positive regulation of t cell differentiation",
    "canonical wnt signaling pathway",
    "defense response to gram-negative bacterium",
    "transforming growth factor beta receptor signaling pathway",
    "positive regulation of nf-kappab signal transduction",
    "regulation of signal transduction by p53 class mediator",
    "regulation of cell migration",
    "apoptotic process",
    "inflammatory response",
    "defense response to virus",
    "defense response to bacterium",
    "regulation of mapk cascade",
    "positive regulation of canonical nf-kappab signal transduction",
    "regulation of canonical nf-kappab signal transduction",
    "regulation of autophagy",
    "macroautophagy",
    "cellular response to starvation",
    "positive regulation of programmed cell death",
    "positive regulation of rna biosynthetic process",
    "positive regulation of dna-binding transcription factor activity",
    "positive regulation of intracellular signal transduction",
    "negative regulation of intracellular signal transduction",
    "cellular response to nitrogen compound"
]

# Filter rows where any keyword appears in the 'Term' column
filtered_df = df[df['Term'].apply(lambda x: any(kw in x for kw in keywords))]

# Display filtered results
from IPython.display import display
display(filtered_df)

# Optionally, save filtered results
filtered_df.to_csv('/content/Filtered_GO_terms.csv', index=False)

import pandas as pd

# Load the GO_BIO.csv file
df = pd.read_csv('/content/GO_BIO.csv')  # Update this path if needed

# Convert all relevant text columns to lowercase for case-insensitive matching
df['Term'] = df['Term'].astype(str).str.lower()

# Define GO-related biological keywords (lowercase for matching)
keywords = [
    "regulation of apoptotic process",
    "negative regulation of apoptotic process",
    "negative regulation of programmed cell death",
    "double-strand break repair",
    "regulation of dna repair",
    "regulation of double-strand break repair via homologous recombination",
    "recombinational repair",
    "positive regulation of double-strand break repair",
    "positive regulation of canonical wnt signaling pathway",
    "regulation of humoral immune response",
    "regulation of immune effector process",
    "negative regulation of intrinsic apoptotic signaling pathway by p53 class mediator",
    "regulation of intrinsic apoptotic signaling pathway in response to dna damage by p53 class mediator",
    "positive regulation of erk1 and erk2 cascade",
    "regulation of complement activation",
    "regulation of oxidative stress-induced intrinsic apoptotic signaling pathway",
    "negative regulation of intrinsic apoptotic signaling pathway in response to dna damage",
    "regulation of programmed cell death",
    "cytoplasmic pattern recognition receptor signaling pathway",
    "regulation of canonical wnt signaling pathway",
    "positive regulation of intrinsic apoptotic signaling pathway",
    "regulation of dna damage response, signal transduction by p53 class mediator",
    "positive regulation of production of molecular mediator of immune response",
    "base-excision repair",
    "chromatin remodeling",
    "dna repair",
    "positive regulation of dna repair",
    "mitophagy",
    "autophagy of mitochondrion",
    "positive regulation of t cell activation",
    "t cell activation",
    "positive regulation of t cell differentiation",
    "canonical wnt signaling pathway",
    "defense response to gram-negative bacterium",
    "transforming growth factor beta receptor signaling pathway",
    "positive regulation of nf-kappab signal transduction",
    "regulation of signal transduction by p53 class mediator",
    "regulation of cell migration",
    "apoptotic process",
    "inflammatory response",
    "defense response to virus",
    "defense response to bacterium",
    "regulation of mapk cascade",
    "positive regulation of canonical nf-kappab signal transduction",
    "regulation of canonical nf-kappab signal transduction",
    "regulation of autophagy",
    "macroautophagy",
    "cellular response to starvation",
    "positive regulation of programmed cell death",
    "positive regulation of rna biosynthetic process",
    "positive regulation of dna-binding transcription factor activity",
    "positive regulation of intracellular signal transduction",
    "negative regulation of intracellular signal transduction",
    "cellular response to nitrogen compound"
]

# Filter rows where any keyword appears in the 'Term' column
filtered_df = df[df['Term'].apply(lambda x: any(kw in x for kw in keywords))]

# Display filtered results
from IPython.display import display
display(filtered_df)

# Optionally, save filtered results
filtered_df.to_csv('/content/Filtered_GO_terms.csv', index=False)

# üìå STEP 1: Install required libraries
!pip install matplotlib pandas seaborn

# üìå STEP 2: Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# üìå STEP 3: Load your data (upload the file in the left panel of Colab first)
file_path = '/content/Combined_GO_filterdataset.csv'  # Adjust if different
df = pd.read_csv(file_path)

# üìå STEP 4: Check the structure
print("Columns:", df.columns)
print(df.head())

# üìå STEP 5: Clean & Prepare Data
# Rename columns if needed
df.columns = [col.strip() for col in df.columns]  # remove whitespace
df = df.sort_values(by='Combined Score', ascending=False).head(20)

# üìå STEP 6: Plot Top 20 GO Terms by Combined Score
plt.figure(figsize=(10, 8))
sns.barplot(data=df, y='Term', x='Combined Score', palette='viridis')
plt.xlabel('Combined Score', fontsize=12)
plt.ylabel('GO Term / Pathway Name', fontsize=12)
plt.title('Top 20 Enriched GO Terms / Pathways (Combined Score)', fontsize=14)
plt.tight_layout()
plt.gca().invert_yaxis()  # Highest score at top
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Load data
df = pd.read_csv('/content/Combined_GO_filterdataset.csv')
df = df.sort_values(by='Combined Score', ascending=False).head(20)

# Plot
plt.figure(figsize=(10, 8))
plt.hlines(y=df['Term'], xmin=0, xmax=df['Combined Score'], color='skyblue')
plt.plot(df['Combined Score'], df['Term'], "o", markersize=8, color='steelblue')
plt.xlabel('Combined Score')
plt.title('Top 20 Enriched GO Terms / Pathways (Lollipop Plot)')
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# Make sure 'Category' column exists in your file
if 'Category' in df.columns:
    plt.figure(figsize=(12, 8))
    sns.scatterplot(data=df.head(20),
                    x='Combined Score',
                    y='Term',
                    size='-log10(p-value)',
                    hue='Category',
                    palette='tab10',
                    sizes=(100, 300))

    plt.title('Bubble Plot: GO Terms by Category, Score, and p-value')
    plt.xlabel('Combined Score')
    plt.ylabel('Term')
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()
else:
    print("No 'Category' column found in the dataset.")

import pandas as pd
import matplotlib.pyplot as plt

# Load your data
df = pd.read_csv('/content/Combined_GO_filterdataset.csv')
df = df.sort_values(by='Combined Score', ascending=False).head(20)

# Set plot resolution and style
plt.figure(figsize=(12, 9), dpi=300)  # Higher DPI for publication-quality
plt.hlines(y=df['Term'], xmin=0, xmax=df['Combined Score'], color='skyblue')
plt.plot(df['Combined Score'], df['Term'], "o", markersize=8, color='steelblue')

# Axis and title formatting
plt.xlabel('Combined Score', fontsize=12)
plt.ylabel('GO Term / Pathway Name', fontsize=12)
plt.title('Top 20 Enriched GO Terms / Pathways (Lollipop Plot)', fontsize=14)
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()

# Save high-resolution image
plt.savefig('Top20_GO_Lollipop_HighRes.png', dpi=600, bbox_inches='tight')
plt.show()

# Install required libraries
!pip install pandas matplotlib seaborn

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
data = pd.read_csv("/content/GO_Pathway_Results.csv")

# Sort data by Combined Score
data = data.sort_values(by="Combined_Score", ascending=True)

# Create figure
plt.figure(figsize=(12,6), dpi=300)

# Create lollipop plot
plt.hlines(y=data["Term"], xmin=0, xmax=data["Combined_Score"], color='skyblue', linewidth=2)
plt.plot(data["Combined_Score"], data["Term"], "o", markersize=7, color='steelblue')

# Customize plot
plt.title("Top Enriched GO/Pathway Terms for Prioritized ceRNA Hubs", fontsize=14)
plt.xlabel("Combined Score", fontsize=12)
plt.ylabel("GO Term / Pathway Name", fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.5)

# Save high-resolution image
plt.tight_layout()
plt.savefig("Lollipop_GO_Pathways.png", dpi=300)
plt.show()

from google.colab import files
files.download('Top20_GO_Lollipop_HighRes.png')

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv('/content/Combined_GO_filterdataset.csv')
df = df.sort_values(by='Combined Score', ascending=False).head(20)

# Prepare dataframe for heatmap
heatmap_data = df[['Term', 'Combined Score']]
heatmap_data.set_index('Term', inplace=True)

# Plot heatmap
plt.figure(figsize=(10, 8), dpi=300)
sns.heatmap(heatmap_data, cmap='viridis', annot=True, linewidths=0.5, fmt=".0f")

plt.title('Top 20 Enriched GO Terms / Pathways - Heatmap', fontsize=14)
plt.xlabel('Combined Score')
plt.ylabel('GO Term / Pathway')
plt.tight_layout()
plt.savefig('GO_heatmap_highres.png', dpi=600)
plt.show()

# Step 1: Install required libraries (if not already installed)
!pip install matplotlib seaborn pandas networkx

# Step 2: Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# Step 3: Upload your file
from google.colab import files
uploaded = files.upload()

# Step 4: Load dataset
df = pd.read_csv("Combined_GO_filterdataset.csv")

# Step 5: Preprocess data
# Drop NaNs and sort by Combined Score
df = df.dropna(subset=["Genes", "Combined Score"])
df = df.sort_values(by="Combined Score", ascending=False)

# Step 6: Heatmap of top 20 terms
top20 = df.head(20)
plt.figure(figsize=(10, 8))
sns.heatmap(top20[["Combined Score"]], annot=True, fmt=".1f", cmap="viridis", yticklabels=top20["Term"])
plt.title("Top 20 Enriched GO Terms / Pathways - Heatmap")
plt.xlabel("Combined Score")
plt.ylabel("GO Term / Pathway")
plt.tight_layout()
plt.savefig("plot1_combined_score_heatmap.png", dpi=300)
plt.show()

# Step 7: Term‚ÄìGene Binary Heatmap (top 15)
top15 = df.head(15)
binary_data = []
term_labels = []
gene_set = set()

# Extract binary matrix
for idx, row in top15.iterrows():
    genes = [g.strip() for g in str(row["Genes"]).split(",") if g]
    gene_set.update(genes)
    term_labels.append(row["Term"])
    binary_data.append(genes)

# Create DataFrame
all_genes = sorted(gene_set)
binary_matrix = pd.DataFrame(0, index=term_labels, columns=all_genes)

for i, genes in enumerate(binary_data):
    for gene in genes:
        binary_matrix.at[term_labels[i], gene] = 1

plt.figure(figsize=(12, 8))
sns.heatmap(binary_matrix, cmap="Blues", cbar=False)
plt.title("GO Term‚ÄìGene Presence Heatmap (Top 15 Terms)")
plt.xlabel("Genes")
plt.ylabel("GO Terms / Pathways")
plt.xticks(rotation=90)
plt.tight_layout()
plt.savefig("plot2_term_gene_binary_heatmap.png", dpi=300)
plt.show()

# Step 8: GO Term‚ÄìGene Network Graph (top 15 terms)
G = nx.Graph()

for idx, row in top15.iterrows():
    term = row["Term"]
    genes = [g.strip() for g in str(row["Genes"]).split(",") if g]
    for gene in genes:
        G.add_node(term, type='term')
        G.add_node(gene, type='gene')
        G.add_edge(term, gene)

plt.figure(figsize=(14, 10))
pos = nx.spring_layout(G, k=0.5, seed=42)
term_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'term']
gene_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'gene']
nx.draw_networkx_nodes(G, pos, nodelist=term_nodes, node_color='lightcoral', node_size=1000, label='GO Term')
nx.draw_networkx_nodes(G, pos, nodelist=gene_nodes, node_color='skyblue', node_size=600, label='Gene')
nx.draw_networkx_edges(G, pos, alpha=0.5)
nx.draw_networkx_labels(G, pos, font_size=8)
plt.title("GO Term‚ÄìGene Network (Top 15 Terms)")
plt.axis("off")
plt.tight_layout()
plt.savefig("plot3_term_gene_network.png", dpi=300)
plt.legend()
plt.show()

import pandas as pd
from collections import defaultdict

# Upload your file first in Colab
from google.colab import files
uploaded = files.upload()

# Load data
df = pd.read_csv("Combined_GO_filterdataset.csv")

# Clean up
df = df.dropna(subset=["Genes", "Combined Score"])

# Initialize frequency counters
gene_freq = defaultdict(int)
gene_weighted_score = defaultdict(float)

# Loop through each row to extract gene information
for _, row in df.iterrows():
    score = row["Combined Score"]
    genes = [g.strip() for g in str(row["Genes"]).split(",") if g.strip()]
    for gene in genes:
        gene_freq[gene] += 1
        gene_weighted_score[gene] += score

# Convert to DataFrame
gene_df = pd.DataFrame({
    "Gene": list(gene_freq.keys()),
    "Frequency": list(gene_freq.values()),
    "Weighted_Score": [gene_weighted_score[g] for g in gene_freq]
})

# Rank genes
gene_df["Score_Rank"] = gene_df["Weighted_Score"].rank(ascending=False, method="dense")
gene_df = gene_df.sort_values(by=["Weighted_Score", "Frequency"], ascending=False)

# Show top 20 crucial genes
gene_df.head(20)

import pandas as pd
from collections import defaultdict

# Upload your file first in Google Colab
from google.colab import files
uploaded = files.upload()

# Load the file
df = pd.read_csv("Combined_GO_filterdataset.csv")

# Drop rows where Genes or Combined Score is missing
df = df.dropna(subset=["Genes", "Combined Score"])

# Initialize dictionaries
gene_freq = defaultdict(int)
gene_weighted_score = defaultdict(float)

# Process each row and split by semicolon
for _, row in df.iterrows():
    score = row["Combined Score"]
    genes = [g.strip() for g in str(row["Genes"]).split(";") if g.strip()]
    for gene in genes:
        gene_freq[gene] += 1
        gene_weighted_score[gene] += score

# Create a DataFrame
gene_df = pd.DataFrame({
    "Gene": list(gene_freq.keys()),
    "Frequency": list(gene_freq.values()),
    "Weighted_Score": [gene_weighted_score[g] for g in gene_freq]
})

# Rank by weighted score
gene_df["Score_Rank"] = gene_df["Weighted_Score"].rank(ascending=False, method="dense")
gene_df = gene_df.sort_values(by=["Weighted_Score", "Frequency"], ascending=False)

# Save or display top results
gene_df.to_csv("Crucial_Genes_Prioritized.csv", index=False)
gene_df.head(20)